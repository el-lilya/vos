[03/27 13:12:55] detectron2 INFO: Rank of current process: 1. World size: 2
[03/27 13:13:01] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]
numpy                   1.21.2
detectron2              0.6 @/netapp/l.lemikhova/anaconda3/envs/vos/lib/python3.9/site-packages/detectron2
Compiler                GCC 9.4
CUDA compiler           CUDA 11.4
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.2 @/netapp/l.lemikhova/anaconda3/envs/vos/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 NVIDIA GeForce GTX 1080 Ti (arch=6.1)
Driver version          470.82.00
CUDA_HOME               /usr/local/cuda
Pillow                  8.4.0
torchvision             0.11.3 @/netapp/l.lemikhova/anaconda3/envs/vos/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220212
iopath                  0.1.9
cv2                     4.5.5
----------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/27 13:13:01] detectron2 INFO: Command line arguments: Namespace(config_file='/netapp/l.lemikhova/projects/VOS/vos/detection/configs/Fruits-Detection/Faster-RCNN/coco_openim/vanilla_from_scratch_7.yaml', resume=True, eval_only=False, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:52933', opts=[], dataset_dir='temp', random_seed=0, inference_config='', test_dataset='', image_corruption_level=0, iou_min=0.1, iou_correct=0.5, min_allowed_score=0.0, savefigdir='./savefig', visualize=0)
[03/27 13:13:01] detectron2 INFO: Contents of args.config_file=/netapp/l.lemikhova/projects/VOS/vos/detection/configs/Fruits-Detection/Faster-RCNN/coco_openim/vanilla_from_scratch_7.yaml:
[38;5;242m# CUDA_VISIBLE_DEVICES=0 python vos/detection/train_net.py --num-gpus 1 --config-file Fruits-Detection/Faster-RCNN/coco_openim/vanilla_from_scratch_8_1.yaml --random-seed 0 --resume[39m
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../../../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGeneralizedRCNN[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;242m# WEIGHTS: "https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl"[39m
[38;5;15m  [39m[38;5;242m# WEIGHTS: "/netapp/l.lemikhova/projects/VOS/vos/detection/data/Faster-RCNN/coco_openim/vanilla_from_scratch_8/random_seed_0/model_final.pth"[39m

[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStandardROIHeads[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(640,[39m[38;5;141m [39m[38;5;141m)[39m[38;5;15m  [39m[38;5;242m# (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m640[39m[38;5;15m  [39m[38;5;242m# 640[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m640[39m[38;5;15m  [39m[38;5;242m# 800[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m('coco_ext_fruits_train',[39m[38;5;141m [39m[38;5;141m'openim_id_fruits_train')[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m('openim_id_fruits_val',[39m[38;5;141m [39m[38;5;141m)[39m
[38;5;15m  [39m[38;5;242m# TEST: ('openim_id_fruits_val', 'coco_ext_fruits_val')[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(12000,[39m[38;5;141m [39m[38;5;141m16000)[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m18000[39m[38;5;15m  [39m[38;5;242m# 17.4 epochs[39m
[38;5;15m  [39m[38;5;242m# MAX_ITER: 200  # 17.4 epochs[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m[38;5;15m  [39m[38;5;242m# Depends on the available memory, 8[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m[38;5;15m  [39m[38;5;242m# 100[39m

[03/27 13:13:02] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=8, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=28, bias=True)
    )
  )
)
[03/27 13:13:02] detectron2.data.datasets.coco INFO: Loaded 3564 images in COCO format from ./data/coco_ext/COCO-Format/train_coco_format.json
[03/27 13:13:03] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 13:13:03] detectron2.data.datasets.coco INFO: Loaded 4776 images in COCO format from ./data/openim_id/COCO-Format/train_coco_format.json
[03/27 13:13:03] detectron2.data.build INFO: Removed 0 images with no usable annotations. 8340 images left.
[03/27 13:13:03] detectron2.data.build INFO: Distribution of instances among all 7 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|   banana   | 8790         |   apple    | 7834         |   orange   | 10346        |
| strawberry | 6366         |   tomato   | 4830         |   lemon    | 1334         |
|    pear    | 710          |            |              |            |              |
|   total    | 40210        |            |              |            |              |[0m
[03/27 13:13:03] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=640, sample_style='choice'), RandomFlip()]
[03/27 13:13:03] detectron2.data.build INFO: Using training sampler TrainingSampler
[03/27 13:13:03] detectron2.data.common INFO: Serializing 8340 elements to byte tensors and concatenating them all ...
[03/27 13:13:03] detectron2.data.common INFO: Serialized dataset takes 4.04 MiB
[03/27 13:13:03] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[03/27 13:13:03] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[03/27 13:13:03] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[03/27 13:13:04] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[03/27 13:13:04] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[03/27 13:13:04] detectron2.engine.train_loop INFO: Starting training from iteration 0
[03/27 13:20:46] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 13:20:46] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 13:20:46] detectron2.data.build INFO: Distribution of instances among all 7 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|   banana   | 176          |   apple    | 304          |   orange   | 851          |
| strawberry | 1022         |   tomato   | 790          |   lemon    | 219          |
|    pear    | 99           |            |              |            |              |
|   total    | 3461         |            |              |            |              |[0m
[03/27 13:20:46] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 13:20:46] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 13:20:46] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 13:20:46] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 13:20:46] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 13:20:52] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0190 s/iter. Inference: 0.0599 s/iter. Eval: 0.0004 s/iter. Total: 0.0793 s/iter. ETA=0:00:32
[03/27 13:20:57] detectron2.evaluation.evaluator INFO: Inference done 69/421. Dataloading: 0.0179 s/iter. Inference: 0.0675 s/iter. Eval: 0.0006 s/iter. Total: 0.0862 s/iter. ETA=0:00:30
[03/27 13:21:02] detectron2.evaluation.evaluator INFO: Inference done 132/421. Dataloading: 0.0170 s/iter. Inference: 0.0653 s/iter. Eval: 0.0007 s/iter. Total: 0.0831 s/iter. ETA=0:00:24
[03/27 13:21:08] detectron2.evaluation.evaluator INFO: Inference done 188/421. Dataloading: 0.0200 s/iter. Inference: 0.0645 s/iter. Eval: 0.0006 s/iter. Total: 0.0853 s/iter. ETA=0:00:19
[03/27 13:21:13] detectron2.evaluation.evaluator INFO: Inference done 250/421. Dataloading: 0.0193 s/iter. Inference: 0.0642 s/iter. Eval: 0.0006 s/iter. Total: 0.0842 s/iter. ETA=0:00:14
[03/27 13:21:18] detectron2.evaluation.evaluator INFO: Inference done 313/421. Dataloading: 0.0194 s/iter. Inference: 0.0633 s/iter. Eval: 0.0006 s/iter. Total: 0.0834 s/iter. ETA=0:00:09
[03/27 13:21:23] detectron2.evaluation.evaluator INFO: Inference done 373/421. Dataloading: 0.0189 s/iter. Inference: 0.0639 s/iter. Eval: 0.0006 s/iter. Total: 0.0834 s/iter. ETA=0:00:04
[03/27 13:21:27] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:35.265877 (0.084774 s / iter per device, on 2 devices)
[03/27 13:21:27] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:26 (0.064038 s / iter per device, on 2 devices)
[03/27 13:29:11] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 13:29:11] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 13:29:11] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 13:29:11] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 13:29:11] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 13:29:11] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 13:29:11] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 13:29:20] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0079 s/iter. Inference: 0.0807 s/iter. Eval: 0.0005 s/iter. Total: 0.0891 s/iter. ETA=0:00:36
[03/27 13:29:26] detectron2.evaluation.evaluator INFO: Inference done 70/421. Dataloading: 0.0190 s/iter. Inference: 0.0677 s/iter. Eval: 0.0005 s/iter. Total: 0.0872 s/iter. ETA=0:00:30
[03/27 13:29:31] detectron2.evaluation.evaluator INFO: Inference done 131/421. Dataloading: 0.0171 s/iter. Inference: 0.0673 s/iter. Eval: 0.0004 s/iter. Total: 0.0849 s/iter. ETA=0:00:24
[03/27 13:29:36] detectron2.evaluation.evaluator INFO: Inference done 182/421. Dataloading: 0.0204 s/iter. Inference: 0.0680 s/iter. Eval: 0.0005 s/iter. Total: 0.0890 s/iter. ETA=0:00:21
[03/27 13:29:41] detectron2.evaluation.evaluator INFO: Inference done 231/421. Dataloading: 0.0220 s/iter. Inference: 0.0697 s/iter. Eval: 0.0005 s/iter. Total: 0.0923 s/iter. ETA=0:00:17
[03/27 13:29:46] detectron2.evaluation.evaluator INFO: Inference done 280/421. Dataloading: 0.0217 s/iter. Inference: 0.0711 s/iter. Eval: 0.0013 s/iter. Total: 0.0942 s/iter. ETA=0:00:13
[03/27 13:29:51] detectron2.evaluation.evaluator INFO: Inference done 336/421. Dataloading: 0.0215 s/iter. Inference: 0.0706 s/iter. Eval: 0.0011 s/iter. Total: 0.0933 s/iter. ETA=0:00:07
[03/27 13:29:56] detectron2.evaluation.evaluator INFO: Inference done 384/421. Dataloading: 0.0229 s/iter. Inference: 0.0706 s/iter. Eval: 0.0011 s/iter. Total: 0.0948 s/iter. ETA=0:00:03
[03/27 13:30:00] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:39.887550 (0.095884 s / iter per device, on 2 devices)
[03/27 13:30:00] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:29 (0.070811 s / iter per device, on 2 devices)
[03/27 13:37:43] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 13:37:43] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 13:37:43] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 13:37:43] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 13:37:43] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 13:37:43] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 13:37:43] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 13:37:49] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0030 s/iter. Inference: 0.0545 s/iter. Eval: 0.0004 s/iter. Total: 0.0579 s/iter. ETA=0:00:23
[03/27 13:37:54] detectron2.evaluation.evaluator INFO: Inference done 75/421. Dataloading: 0.0153 s/iter. Inference: 0.0614 s/iter. Eval: 0.0005 s/iter. Total: 0.0772 s/iter. ETA=0:00:26
[03/27 13:37:59] detectron2.evaluation.evaluator INFO: Inference done 128/421. Dataloading: 0.0179 s/iter. Inference: 0.0665 s/iter. Eval: 0.0005 s/iter. Total: 0.0850 s/iter. ETA=0:00:24
[03/27 13:38:04] detectron2.evaluation.evaluator INFO: Inference done 186/421. Dataloading: 0.0186 s/iter. Inference: 0.0664 s/iter. Eval: 0.0005 s/iter. Total: 0.0856 s/iter. ETA=0:00:20
[03/27 13:38:09] detectron2.evaluation.evaluator INFO: Inference done 245/421. Dataloading: 0.0213 s/iter. Inference: 0.0636 s/iter. Eval: 0.0005 s/iter. Total: 0.0855 s/iter. ETA=0:00:15
[03/27 13:38:14] detectron2.evaluation.evaluator INFO: Inference done 307/421. Dataloading: 0.0220 s/iter. Inference: 0.0623 s/iter. Eval: 0.0004 s/iter. Total: 0.0849 s/iter. ETA=0:00:09
[03/27 13:38:19] detectron2.evaluation.evaluator INFO: Inference done 366/421. Dataloading: 0.0222 s/iter. Inference: 0.0621 s/iter. Eval: 0.0005 s/iter. Total: 0.0849 s/iter. ETA=0:00:04
[03/27 13:38:24] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:35.064448 (0.084290 s / iter per device, on 2 devices)
[03/27 13:38:24] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:25 (0.061983 s / iter per device, on 2 devices)
[03/27 13:46:17] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 13:46:17] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 13:46:17] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 13:46:17] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 13:46:17] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 13:46:17] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 13:46:17] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 13:46:25] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0177 s/iter. Inference: 0.0530 s/iter. Eval: 0.0005 s/iter. Total: 0.0711 s/iter. ETA=0:00:29
[03/27 13:46:30] detectron2.evaluation.evaluator INFO: Inference done 63/421. Dataloading: 0.0148 s/iter. Inference: 0.0784 s/iter. Eval: 0.0010 s/iter. Total: 0.0943 s/iter. ETA=0:00:33
[03/27 13:46:36] detectron2.evaluation.evaluator INFO: Inference done 116/421. Dataloading: 0.0198 s/iter. Inference: 0.0743 s/iter. Eval: 0.0008 s/iter. Total: 0.0952 s/iter. ETA=0:00:29
[03/27 13:46:41] detectron2.evaluation.evaluator INFO: Inference done 172/421. Dataloading: 0.0183 s/iter. Inference: 0.0740 s/iter. Eval: 0.0009 s/iter. Total: 0.0934 s/iter. ETA=0:00:23
[03/27 13:46:46] detectron2.evaluation.evaluator INFO: Inference done 221/421. Dataloading: 0.0201 s/iter. Inference: 0.0744 s/iter. Eval: 0.0009 s/iter. Total: 0.0955 s/iter. ETA=0:00:19
[03/27 13:46:51] detectron2.evaluation.evaluator INFO: Inference done 275/421. Dataloading: 0.0212 s/iter. Inference: 0.0728 s/iter. Eval: 0.0008 s/iter. Total: 0.0949 s/iter. ETA=0:00:13
[03/27 13:46:56] detectron2.evaluation.evaluator INFO: Inference done 328/421. Dataloading: 0.0227 s/iter. Inference: 0.0715 s/iter. Eval: 0.0007 s/iter. Total: 0.0951 s/iter. ETA=0:00:08
[03/27 13:47:01] detectron2.evaluation.evaluator INFO: Inference done 379/421. Dataloading: 0.0242 s/iter. Inference: 0.0705 s/iter. Eval: 0.0007 s/iter. Total: 0.0955 s/iter. ETA=0:00:04
[03/27 13:47:05] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:40.510410 (0.097381 s / iter per device, on 2 devices)
[03/27 13:47:05] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.069428 s / iter per device, on 2 devices)
[03/27 13:54:48] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 13:54:48] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 13:54:49] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 13:54:49] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 13:54:49] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 13:54:49] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 13:54:49] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 13:54:55] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0155 s/iter. Inference: 0.0592 s/iter. Eval: 0.0004 s/iter. Total: 0.0751 s/iter. ETA=0:00:30
[03/27 13:55:00] detectron2.evaluation.evaluator INFO: Inference done 71/421. Dataloading: 0.0158 s/iter. Inference: 0.0667 s/iter. Eval: 0.0006 s/iter. Total: 0.0833 s/iter. ETA=0:00:29
[03/27 13:55:06] detectron2.evaluation.evaluator INFO: Inference done 130/421. Dataloading: 0.0186 s/iter. Inference: 0.0651 s/iter. Eval: 0.0006 s/iter. Total: 0.0845 s/iter. ETA=0:00:24
[03/27 13:55:11] detectron2.evaluation.evaluator INFO: Inference done 190/421. Dataloading: 0.0187 s/iter. Inference: 0.0650 s/iter. Eval: 0.0006 s/iter. Total: 0.0844 s/iter. ETA=0:00:19
[03/27 13:55:16] detectron2.evaluation.evaluator INFO: Inference done 248/421. Dataloading: 0.0197 s/iter. Inference: 0.0647 s/iter. Eval: 0.0006 s/iter. Total: 0.0850 s/iter. ETA=0:00:14
[03/27 13:55:21] detectron2.evaluation.evaluator INFO: Inference done 310/421. Dataloading: 0.0188 s/iter. Inference: 0.0647 s/iter. Eval: 0.0006 s/iter. Total: 0.0842 s/iter. ETA=0:00:09
[03/27 13:55:26] detectron2.evaluation.evaluator INFO: Inference done 367/421. Dataloading: 0.0194 s/iter. Inference: 0.0648 s/iter. Eval: 0.0005 s/iter. Total: 0.0848 s/iter. ETA=0:00:04
[03/27 13:55:31] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:35.633780 (0.085658 s / iter per device, on 2 devices)
[03/27 13:55:31] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:26 (0.064772 s / iter per device, on 2 devices)
[03/27 14:03:23] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 14:03:23] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 14:03:23] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 14:03:23] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 14:03:23] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 14:03:23] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 14:03:23] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 14:03:33] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0424 s/iter. Inference: 0.0563 s/iter. Eval: 0.0003 s/iter. Total: 0.0990 s/iter. ETA=0:00:40
[03/27 14:03:38] detectron2.evaluation.evaluator INFO: Inference done 56/421. Dataloading: 0.0426 s/iter. Inference: 0.0669 s/iter. Eval: 0.0005 s/iter. Total: 0.1100 s/iter. ETA=0:00:40
[03/27 14:03:43] detectron2.evaluation.evaluator INFO: Inference done 103/421. Dataloading: 0.0351 s/iter. Inference: 0.0730 s/iter. Eval: 0.0005 s/iter. Total: 0.1088 s/iter. ETA=0:00:34
[03/27 14:03:48] detectron2.evaluation.evaluator INFO: Inference done 155/421. Dataloading: 0.0327 s/iter. Inference: 0.0712 s/iter. Eval: 0.0006 s/iter. Total: 0.1048 s/iter. ETA=0:00:27
[03/27 14:03:53] detectron2.evaluation.evaluator INFO: Inference done 204/421. Dataloading: 0.0326 s/iter. Inference: 0.0709 s/iter. Eval: 0.0006 s/iter. Total: 0.1044 s/iter. ETA=0:00:22
[03/27 14:03:58] detectron2.evaluation.evaluator INFO: Inference done 256/421. Dataloading: 0.0308 s/iter. Inference: 0.0712 s/iter. Eval: 0.0006 s/iter. Total: 0.1030 s/iter. ETA=0:00:16
[03/27 14:04:03] detectron2.evaluation.evaluator INFO: Inference done 310/421. Dataloading: 0.0298 s/iter. Inference: 0.0706 s/iter. Eval: 0.0006 s/iter. Total: 0.1012 s/iter. ETA=0:00:11
[03/27 14:04:08] detectron2.evaluation.evaluator INFO: Inference done 366/421. Dataloading: 0.0283 s/iter. Inference: 0.0702 s/iter. Eval: 0.0006 s/iter. Total: 0.0994 s/iter. ETA=0:00:05
[03/27 14:04:13] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:41.118900 (0.098844 s / iter per device, on 2 devices)
[03/27 14:04:13] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.068877 s / iter per device, on 2 devices)
[03/27 14:11:54] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 14:11:54] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 14:11:54] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 14:11:54] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 14:11:54] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 14:11:54] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 14:11:54] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 14:12:00] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0097 s/iter. Inference: 0.0812 s/iter. Eval: 0.0004 s/iter. Total: 0.0914 s/iter. ETA=0:00:37
[03/27 14:12:05] detectron2.evaluation.evaluator INFO: Inference done 60/421. Dataloading: 0.0248 s/iter. Inference: 0.0763 s/iter. Eval: 0.0004 s/iter. Total: 0.1015 s/iter. ETA=0:00:36
[03/27 14:12:11] detectron2.evaluation.evaluator INFO: Inference done 112/421. Dataloading: 0.0242 s/iter. Inference: 0.0744 s/iter. Eval: 0.0005 s/iter. Total: 0.0992 s/iter. ETA=0:00:30
[03/27 14:12:16] detectron2.evaluation.evaluator INFO: Inference done 162/421. Dataloading: 0.0237 s/iter. Inference: 0.0755 s/iter. Eval: 0.0006 s/iter. Total: 0.0999 s/iter. ETA=0:00:25
[03/27 14:12:21] detectron2.evaluation.evaluator INFO: Inference done 221/421. Dataloading: 0.0230 s/iter. Inference: 0.0722 s/iter. Eval: 0.0006 s/iter. Total: 0.0958 s/iter. ETA=0:00:19
[03/27 14:12:26] detectron2.evaluation.evaluator INFO: Inference done 279/421. Dataloading: 0.0240 s/iter. Inference: 0.0691 s/iter. Eval: 0.0006 s/iter. Total: 0.0938 s/iter. ETA=0:00:13
[03/27 14:12:31] detectron2.evaluation.evaluator INFO: Inference done 332/421. Dataloading: 0.0234 s/iter. Inference: 0.0702 s/iter. Eval: 0.0005 s/iter. Total: 0.0942 s/iter. ETA=0:00:08
[03/27 14:12:36] detectron2.evaluation.evaluator INFO: Inference done 384/421. Dataloading: 0.0232 s/iter. Inference: 0.0708 s/iter. Eval: 0.0005 s/iter. Total: 0.0946 s/iter. ETA=0:00:03
[03/27 14:12:39] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:39.418919 (0.094757 s / iter per device, on 2 devices)
[03/27 14:12:39] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:29 (0.070434 s / iter per device, on 2 devices)
[03/27 14:20:24] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 14:20:24] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 14:20:24] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 14:20:24] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 14:20:24] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 14:20:24] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 14:20:24] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 14:20:33] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0037 s/iter. Inference: 0.0609 s/iter. Eval: 0.0004 s/iter. Total: 0.0651 s/iter. ETA=0:00:26
[03/27 14:20:38] detectron2.evaluation.evaluator INFO: Inference done 60/421. Dataloading: 0.0231 s/iter. Inference: 0.0757 s/iter. Eval: 0.0004 s/iter. Total: 0.0993 s/iter. ETA=0:00:35
[03/27 14:20:44] detectron2.evaluation.evaluator INFO: Inference done 113/421. Dataloading: 0.0252 s/iter. Inference: 0.0717 s/iter. Eval: 0.0006 s/iter. Total: 0.0976 s/iter. ETA=0:00:30
[03/27 14:20:49] detectron2.evaluation.evaluator INFO: Inference done 180/421. Dataloading: 0.0226 s/iter. Inference: 0.0657 s/iter. Eval: 0.0006 s/iter. Total: 0.0890 s/iter. ETA=0:00:21
[03/27 14:20:54] detectron2.evaluation.evaluator INFO: Inference done 248/421. Dataloading: 0.0219 s/iter. Inference: 0.0624 s/iter. Eval: 0.0005 s/iter. Total: 0.0850 s/iter. ETA=0:00:14
[03/27 14:20:59] detectron2.evaluation.evaluator INFO: Inference done 295/421. Dataloading: 0.0239 s/iter. Inference: 0.0643 s/iter. Eval: 0.0005 s/iter. Total: 0.0888 s/iter. ETA=0:00:11
[03/27 14:21:04] detectron2.evaluation.evaluator INFO: Inference done 353/421. Dataloading: 0.0236 s/iter. Inference: 0.0641 s/iter. Eval: 0.0006 s/iter. Total: 0.0884 s/iter. ETA=0:00:06
[03/27 14:21:09] detectron2.evaluation.evaluator INFO: Inference done 402/421. Dataloading: 0.0234 s/iter. Inference: 0.0661 s/iter. Eval: 0.0006 s/iter. Total: 0.0902 s/iter. ETA=0:00:01
[03/27 14:21:11] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:37.695134 (0.090613 s / iter per device, on 2 devices)
[03/27 14:21:11] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:27 (0.065775 s / iter per device, on 2 devices)
[03/27 14:28:48] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 14:28:48] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 14:28:48] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 14:28:48] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 14:28:48] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 14:28:48] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 14:28:48] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 14:28:54] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0157 s/iter. Inference: 0.0671 s/iter. Eval: 0.0004 s/iter. Total: 0.0832 s/iter. ETA=0:00:34
[03/27 14:28:59] detectron2.evaluation.evaluator INFO: Inference done 58/421. Dataloading: 0.0347 s/iter. Inference: 0.0696 s/iter. Eval: 0.0007 s/iter. Total: 0.1052 s/iter. ETA=0:00:38
[03/27 14:29:05] detectron2.evaluation.evaluator INFO: Inference done 103/421. Dataloading: 0.0380 s/iter. Inference: 0.0700 s/iter. Eval: 0.0005 s/iter. Total: 0.1086 s/iter. ETA=0:00:34
[03/27 14:29:10] detectron2.evaluation.evaluator INFO: Inference done 147/421. Dataloading: 0.0403 s/iter. Inference: 0.0697 s/iter. Eval: 0.0005 s/iter. Total: 0.1106 s/iter. ETA=0:00:30
[03/27 14:29:15] detectron2.evaluation.evaluator INFO: Inference done 203/421. Dataloading: 0.0348 s/iter. Inference: 0.0696 s/iter. Eval: 0.0005 s/iter. Total: 0.1049 s/iter. ETA=0:00:22
[03/27 14:29:20] detectron2.evaluation.evaluator INFO: Inference done 259/421. Dataloading: 0.0308 s/iter. Inference: 0.0701 s/iter. Eval: 0.0005 s/iter. Total: 0.1016 s/iter. ETA=0:00:16
[03/27 14:29:25] detectron2.evaluation.evaluator INFO: Inference done 317/421. Dataloading: 0.0286 s/iter. Inference: 0.0696 s/iter. Eval: 0.0005 s/iter. Total: 0.0988 s/iter. ETA=0:00:10
[03/27 14:29:30] detectron2.evaluation.evaluator INFO: Inference done 375/421. Dataloading: 0.0267 s/iter. Inference: 0.0696 s/iter. Eval: 0.0005 s/iter. Total: 0.0969 s/iter. ETA=0:00:04
[03/27 14:29:35] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:40.683095 (0.097796 s / iter per device, on 2 devices)
[03/27 14:29:35] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.069433 s / iter per device, on 2 devices)
[03/27 14:36:52] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 14:36:52] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 14:36:52] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 14:36:52] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 14:36:52] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 14:36:52] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 14:36:52] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 14:37:01] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0107 s/iter. Inference: 0.0571 s/iter. Eval: 0.0003 s/iter. Total: 0.0681 s/iter. ETA=0:00:27
[03/27 14:37:07] detectron2.evaluation.evaluator INFO: Inference done 61/421. Dataloading: 0.0276 s/iter. Inference: 0.0691 s/iter. Eval: 0.0008 s/iter. Total: 0.0978 s/iter. ETA=0:00:35
[03/27 14:37:12] detectron2.evaluation.evaluator INFO: Inference done 120/421. Dataloading: 0.0229 s/iter. Inference: 0.0674 s/iter. Eval: 0.0007 s/iter. Total: 0.0913 s/iter. ETA=0:00:27
[03/27 14:37:17] detectron2.evaluation.evaluator INFO: Inference done 178/421. Dataloading: 0.0213 s/iter. Inference: 0.0680 s/iter. Eval: 0.0006 s/iter. Total: 0.0900 s/iter. ETA=0:00:21
[03/27 14:37:22] detectron2.evaluation.evaluator INFO: Inference done 232/421. Dataloading: 0.0230 s/iter. Inference: 0.0672 s/iter. Eval: 0.0005 s/iter. Total: 0.0909 s/iter. ETA=0:00:17
[03/27 14:37:27] detectron2.evaluation.evaluator INFO: Inference done 290/421. Dataloading: 0.0220 s/iter. Inference: 0.0675 s/iter. Eval: 0.0006 s/iter. Total: 0.0902 s/iter. ETA=0:00:11
[03/27 14:37:32] detectron2.evaluation.evaluator INFO: Inference done 350/421. Dataloading: 0.0213 s/iter. Inference: 0.0671 s/iter. Eval: 0.0005 s/iter. Total: 0.0891 s/iter. ETA=0:00:06
[03/27 14:37:37] detectron2.evaluation.evaluator INFO: Inference done 400/421. Dataloading: 0.0228 s/iter. Inference: 0.0674 s/iter. Eval: 0.0005 s/iter. Total: 0.0909 s/iter. ETA=0:00:01
[03/27 14:37:40] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:38.559464 (0.092691 s / iter per device, on 2 devices)
[03/27 14:37:40] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.067514 s / iter per device, on 2 devices)
[03/27 14:44:52] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 14:44:52] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 14:44:52] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 14:44:52] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 14:44:52] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 14:44:52] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 14:44:52] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 14:44:59] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0133 s/iter. Inference: 0.0829 s/iter. Eval: 0.0003 s/iter. Total: 0.0965 s/iter. ETA=0:00:39
[03/27 14:45:04] detectron2.evaluation.evaluator INFO: Inference done 66/421. Dataloading: 0.0191 s/iter. Inference: 0.0729 s/iter. Eval: 0.0004 s/iter. Total: 0.0926 s/iter. ETA=0:00:32
[03/27 14:45:10] detectron2.evaluation.evaluator INFO: Inference done 121/421. Dataloading: 0.0186 s/iter. Inference: 0.0733 s/iter. Eval: 0.0004 s/iter. Total: 0.0925 s/iter. ETA=0:00:27
[03/27 14:45:15] detectron2.evaluation.evaluator INFO: Inference done 175/421. Dataloading: 0.0191 s/iter. Inference: 0.0734 s/iter. Eval: 0.0004 s/iter. Total: 0.0930 s/iter. ETA=0:00:22
[03/27 14:45:20] detectron2.evaluation.evaluator INFO: Inference done 234/421. Dataloading: 0.0191 s/iter. Inference: 0.0718 s/iter. Eval: 0.0004 s/iter. Total: 0.0914 s/iter. ETA=0:00:17
[03/27 14:45:25] detectron2.evaluation.evaluator INFO: Inference done 294/421. Dataloading: 0.0191 s/iter. Inference: 0.0702 s/iter. Eval: 0.0004 s/iter. Total: 0.0898 s/iter. ETA=0:00:11
[03/27 14:45:30] detectron2.evaluation.evaluator INFO: Inference done 355/421. Dataloading: 0.0177 s/iter. Inference: 0.0702 s/iter. Eval: 0.0005 s/iter. Total: 0.0885 s/iter. ETA=0:00:05
[03/27 14:45:35] detectron2.evaluation.evaluator INFO: Inference done 406/421. Dataloading: 0.0191 s/iter. Inference: 0.0701 s/iter. Eval: 0.0005 s/iter. Total: 0.0898 s/iter. ETA=0:00:01
[03/27 14:45:37] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:38.220279 (0.091876 s / iter per device, on 2 devices)
[03/27 14:45:37] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:29 (0.070209 s / iter per device, on 2 devices)
[03/27 14:52:51] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 14:52:51] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 14:52:51] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 14:52:51] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 14:52:51] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 14:52:51] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 14:52:51] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 14:53:03] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0053 s/iter. Inference: 0.0821 s/iter. Eval: 0.0003 s/iter. Total: 0.0877 s/iter. ETA=0:00:35
[03/27 14:53:08] detectron2.evaluation.evaluator INFO: Inference done 60/421. Dataloading: 0.0249 s/iter. Inference: 0.0758 s/iter. Eval: 0.0003 s/iter. Total: 0.1011 s/iter. ETA=0:00:36
[03/27 14:53:14] detectron2.evaluation.evaluator INFO: Inference done 119/421. Dataloading: 0.0178 s/iter. Inference: 0.0750 s/iter. Eval: 0.0005 s/iter. Total: 0.0933 s/iter. ETA=0:00:28
[03/27 14:53:19] detectron2.evaluation.evaluator INFO: Inference done 173/421. Dataloading: 0.0196 s/iter. Inference: 0.0731 s/iter. Eval: 0.0007 s/iter. Total: 0.0934 s/iter. ETA=0:00:23
[03/27 14:53:24] detectron2.evaluation.evaluator INFO: Inference done 229/421. Dataloading: 0.0201 s/iter. Inference: 0.0717 s/iter. Eval: 0.0006 s/iter. Total: 0.0925 s/iter. ETA=0:00:17
[03/27 14:53:29] detectron2.evaluation.evaluator INFO: Inference done 287/421. Dataloading: 0.0200 s/iter. Inference: 0.0708 s/iter. Eval: 0.0006 s/iter. Total: 0.0915 s/iter. ETA=0:00:12
[03/27 14:53:34] detectron2.evaluation.evaluator INFO: Inference done 344/421. Dataloading: 0.0192 s/iter. Inference: 0.0712 s/iter. Eval: 0.0005 s/iter. Total: 0.0910 s/iter. ETA=0:00:07
[03/27 14:53:39] detectron2.evaluation.evaluator INFO: Inference done 402/421. Dataloading: 0.0188 s/iter. Inference: 0.0710 s/iter. Eval: 0.0006 s/iter. Total: 0.0904 s/iter. ETA=0:00:01
[03/27 14:53:41] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:37.999745 (0.091346 s / iter per device, on 2 devices)
[03/27 14:53:41] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:29 (0.070691 s / iter per device, on 2 devices)
[03/27 15:00:55] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 15:00:55] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 15:00:55] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 15:00:55] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 15:00:55] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 15:00:55] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 15:00:55] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 15:01:01] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0156 s/iter. Inference: 0.0607 s/iter. Eval: 0.0003 s/iter. Total: 0.0766 s/iter. ETA=0:00:31
[03/27 15:01:06] detectron2.evaluation.evaluator INFO: Inference done 64/421. Dataloading: 0.0233 s/iter. Inference: 0.0704 s/iter. Eval: 0.0003 s/iter. Total: 0.0941 s/iter. ETA=0:00:33
[03/27 15:01:11] detectron2.evaluation.evaluator INFO: Inference done 123/421. Dataloading: 0.0191 s/iter. Inference: 0.0703 s/iter. Eval: 0.0003 s/iter. Total: 0.0900 s/iter. ETA=0:00:26
[03/27 15:01:17] detectron2.evaluation.evaluator INFO: Inference done 178/421. Dataloading: 0.0194 s/iter. Inference: 0.0705 s/iter. Eval: 0.0004 s/iter. Total: 0.0904 s/iter. ETA=0:00:21
[03/27 15:01:22] detectron2.evaluation.evaluator INFO: Inference done 236/421. Dataloading: 0.0199 s/iter. Inference: 0.0691 s/iter. Eval: 0.0004 s/iter. Total: 0.0895 s/iter. ETA=0:00:16
[03/27 15:01:27] detectron2.evaluation.evaluator INFO: Inference done 294/421. Dataloading: 0.0198 s/iter. Inference: 0.0685 s/iter. Eval: 0.0004 s/iter. Total: 0.0888 s/iter. ETA=0:00:11
[03/27 15:01:32] detectron2.evaluation.evaluator INFO: Inference done 354/421. Dataloading: 0.0189 s/iter. Inference: 0.0686 s/iter. Eval: 0.0004 s/iter. Total: 0.0880 s/iter. ETA=0:00:05
[03/27 15:01:37] detectron2.evaluation.evaluator INFO: Inference done 410/421. Dataloading: 0.0198 s/iter. Inference: 0.0680 s/iter. Eval: 0.0004 s/iter. Total: 0.0884 s/iter. ETA=0:00:00
[03/27 15:01:38] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:37.266667 (0.089583 s / iter per device, on 2 devices)
[03/27 15:01:38] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.068183 s / iter per device, on 2 devices)
[03/27 15:08:55] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 15:08:55] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 15:08:55] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 15:08:55] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 15:08:55] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 15:08:55] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 15:08:55] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 15:09:04] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0100 s/iter. Inference: 0.0641 s/iter. Eval: 0.0003 s/iter. Total: 0.0744 s/iter. ETA=0:00:30
[03/27 15:09:09] detectron2.evaluation.evaluator INFO: Inference done 65/421. Dataloading: 0.0215 s/iter. Inference: 0.0688 s/iter. Eval: 0.0006 s/iter. Total: 0.0911 s/iter. ETA=0:00:32
[03/27 15:09:14] detectron2.evaluation.evaluator INFO: Inference done 120/421. Dataloading: 0.0231 s/iter. Inference: 0.0677 s/iter. Eval: 0.0005 s/iter. Total: 0.0915 s/iter. ETA=0:00:27
[03/27 15:09:19] detectron2.evaluation.evaluator INFO: Inference done 175/421. Dataloading: 0.0232 s/iter. Inference: 0.0683 s/iter. Eval: 0.0005 s/iter. Total: 0.0920 s/iter. ETA=0:00:22
[03/27 15:09:25] detectron2.evaluation.evaluator INFO: Inference done 229/421. Dataloading: 0.0244 s/iter. Inference: 0.0672 s/iter. Eval: 0.0004 s/iter. Total: 0.0922 s/iter. ETA=0:00:17
[03/27 15:09:30] detectron2.evaluation.evaluator INFO: Inference done 288/421. Dataloading: 0.0241 s/iter. Inference: 0.0662 s/iter. Eval: 0.0004 s/iter. Total: 0.0908 s/iter. ETA=0:00:12
[03/27 15:09:35] detectron2.evaluation.evaluator INFO: Inference done 342/421. Dataloading: 0.0233 s/iter. Inference: 0.0673 s/iter. Eval: 0.0004 s/iter. Total: 0.0912 s/iter. ETA=0:00:07
[03/27 15:09:40] detectron2.evaluation.evaluator INFO: Inference done 394/421. Dataloading: 0.0229 s/iter. Inference: 0.0684 s/iter. Eval: 0.0004 s/iter. Total: 0.0919 s/iter. ETA=0:00:02
[03/27 15:09:42] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:38.581186 (0.092743 s / iter per device, on 2 devices)
[03/27 15:09:42] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.068243 s / iter per device, on 2 devices)
[03/27 15:16:56] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 15:16:56] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 15:16:56] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 15:16:56] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 15:16:56] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 15:16:56] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 15:16:56] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 15:17:02] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0046 s/iter. Inference: 0.0683 s/iter. Eval: 0.0003 s/iter. Total: 0.0732 s/iter. ETA=0:00:30
[03/27 15:17:07] detectron2.evaluation.evaluator INFO: Inference done 67/421. Dataloading: 0.0192 s/iter. Inference: 0.0682 s/iter. Eval: 0.0003 s/iter. Total: 0.0880 s/iter. ETA=0:00:31
[03/27 15:17:12] detectron2.evaluation.evaluator INFO: Inference done 118/421. Dataloading: 0.0230 s/iter. Inference: 0.0693 s/iter. Eval: 0.0003 s/iter. Total: 0.0928 s/iter. ETA=0:00:28
[03/27 15:17:18] detectron2.evaluation.evaluator INFO: Inference done 176/421. Dataloading: 0.0225 s/iter. Inference: 0.0680 s/iter. Eval: 0.0003 s/iter. Total: 0.0910 s/iter. ETA=0:00:22
[03/27 15:17:23] detectron2.evaluation.evaluator INFO: Inference done 234/421. Dataloading: 0.0220 s/iter. Inference: 0.0676 s/iter. Eval: 0.0004 s/iter. Total: 0.0902 s/iter. ETA=0:00:16
[03/27 15:17:28] detectron2.evaluation.evaluator INFO: Inference done 291/421. Dataloading: 0.0206 s/iter. Inference: 0.0685 s/iter. Eval: 0.0004 s/iter. Total: 0.0897 s/iter. ETA=0:00:11
[03/27 15:17:33] detectron2.evaluation.evaluator INFO: Inference done 345/421. Dataloading: 0.0215 s/iter. Inference: 0.0685 s/iter. Eval: 0.0004 s/iter. Total: 0.0905 s/iter. ETA=0:00:06
[03/27 15:17:38] detectron2.evaluation.evaluator INFO: Inference done 399/421. Dataloading: 0.0218 s/iter. Inference: 0.0686 s/iter. Eval: 0.0004 s/iter. Total: 0.0909 s/iter. ETA=0:00:01
[03/27 15:17:40] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:38.381976 (0.092264 s / iter per device, on 2 devices)
[03/27 15:17:40] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.068573 s / iter per device, on 2 devices)
[03/27 15:24:55] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 15:24:55] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 15:24:55] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 15:24:55] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 15:24:55] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 15:24:55] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 15:24:55] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 15:25:04] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0217 s/iter. Inference: 0.0586 s/iter. Eval: 0.0003 s/iter. Total: 0.0806 s/iter. ETA=0:00:33
[03/27 15:25:09] detectron2.evaluation.evaluator INFO: Inference done 67/421. Dataloading: 0.0203 s/iter. Inference: 0.0689 s/iter. Eval: 0.0006 s/iter. Total: 0.0898 s/iter. ETA=0:00:31
[03/27 15:25:14] detectron2.evaluation.evaluator INFO: Inference done 124/421. Dataloading: 0.0195 s/iter. Inference: 0.0691 s/iter. Eval: 0.0005 s/iter. Total: 0.0891 s/iter. ETA=0:00:26
[03/27 15:25:19] detectron2.evaluation.evaluator INFO: Inference done 180/421. Dataloading: 0.0207 s/iter. Inference: 0.0683 s/iter. Eval: 0.0004 s/iter. Total: 0.0896 s/iter. ETA=0:00:21
[03/27 15:25:24] detectron2.evaluation.evaluator INFO: Inference done 238/421. Dataloading: 0.0210 s/iter. Inference: 0.0675 s/iter. Eval: 0.0004 s/iter. Total: 0.0890 s/iter. ETA=0:00:16
[03/27 15:25:29] detectron2.evaluation.evaluator INFO: Inference done 292/421. Dataloading: 0.0217 s/iter. Inference: 0.0676 s/iter. Eval: 0.0004 s/iter. Total: 0.0898 s/iter. ETA=0:00:11
[03/27 15:25:35] detectron2.evaluation.evaluator INFO: Inference done 346/421. Dataloading: 0.0221 s/iter. Inference: 0.0680 s/iter. Eval: 0.0004 s/iter. Total: 0.0906 s/iter. ETA=0:00:06
[03/27 15:25:40] detectron2.evaluation.evaluator INFO: Inference done 398/421. Dataloading: 0.0226 s/iter. Inference: 0.0684 s/iter. Eval: 0.0004 s/iter. Total: 0.0914 s/iter. ETA=0:00:02
[03/27 15:25:42] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:38.455470 (0.092441 s / iter per device, on 2 devices)
[03/27 15:25:42] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.068425 s / iter per device, on 2 devices)
[03/27 15:32:57] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 15:32:57] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 15:32:57] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 15:32:57] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 15:32:57] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 15:32:57] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 15:32:57] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 15:33:03] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0107 s/iter. Inference: 0.0613 s/iter. Eval: 0.0003 s/iter. Total: 0.0723 s/iter. ETA=0:00:29
[03/27 15:33:08] detectron2.evaluation.evaluator INFO: Inference done 67/421. Dataloading: 0.0199 s/iter. Inference: 0.0701 s/iter. Eval: 0.0003 s/iter. Total: 0.0904 s/iter. ETA=0:00:31
[03/27 15:33:13] detectron2.evaluation.evaluator INFO: Inference done 120/421. Dataloading: 0.0241 s/iter. Inference: 0.0682 s/iter. Eval: 0.0003 s/iter. Total: 0.0927 s/iter. ETA=0:00:27
[03/27 15:33:18] detectron2.evaluation.evaluator INFO: Inference done 177/421. Dataloading: 0.0220 s/iter. Inference: 0.0687 s/iter. Eval: 0.0004 s/iter. Total: 0.0912 s/iter. ETA=0:00:22
[03/27 15:33:23] detectron2.evaluation.evaluator INFO: Inference done 229/421. Dataloading: 0.0246 s/iter. Inference: 0.0677 s/iter. Eval: 0.0004 s/iter. Total: 0.0928 s/iter. ETA=0:00:17
[03/27 15:33:28] detectron2.evaluation.evaluator INFO: Inference done 290/421. Dataloading: 0.0228 s/iter. Inference: 0.0674 s/iter. Eval: 0.0005 s/iter. Total: 0.0907 s/iter. ETA=0:00:11
[03/27 15:33:33] detectron2.evaluation.evaluator INFO: Inference done 348/421. Dataloading: 0.0222 s/iter. Inference: 0.0673 s/iter. Eval: 0.0005 s/iter. Total: 0.0901 s/iter. ETA=0:00:06
[03/27 15:33:38] detectron2.evaluation.evaluator INFO: Inference done 404/421. Dataloading: 0.0216 s/iter. Inference: 0.0678 s/iter. Eval: 0.0005 s/iter. Total: 0.0900 s/iter. ETA=0:00:01
[03/27 15:33:40] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:37.791120 (0.090844 s / iter per device, on 2 devices)
[03/27 15:33:40] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.067564 s / iter per device, on 2 devices)
[03/27 15:40:56] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 15:40:56] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 15:40:56] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 15:40:56] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 15:40:56] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 15:40:56] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 15:40:56] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 15:41:05] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0235 s/iter. Inference: 0.0645 s/iter. Eval: 0.0003 s/iter. Total: 0.0883 s/iter. ETA=0:00:36
[03/27 15:41:11] detectron2.evaluation.evaluator INFO: Inference done 67/421. Dataloading: 0.0235 s/iter. Inference: 0.0660 s/iter. Eval: 0.0003 s/iter. Total: 0.0900 s/iter. ETA=0:00:31
[03/27 15:41:16] detectron2.evaluation.evaluator INFO: Inference done 126/421. Dataloading: 0.0210 s/iter. Inference: 0.0666 s/iter. Eval: 0.0003 s/iter. Total: 0.0881 s/iter. ETA=0:00:25
[03/27 15:41:21] detectron2.evaluation.evaluator INFO: Inference done 176/421. Dataloading: 0.0253 s/iter. Inference: 0.0660 s/iter. Eval: 0.0003 s/iter. Total: 0.0919 s/iter. ETA=0:00:22
[03/27 15:41:26] detectron2.evaluation.evaluator INFO: Inference done 231/421. Dataloading: 0.0255 s/iter. Inference: 0.0660 s/iter. Eval: 0.0004 s/iter. Total: 0.0919 s/iter. ETA=0:00:17
[03/27 15:41:31] detectron2.evaluation.evaluator INFO: Inference done 289/421. Dataloading: 0.0245 s/iter. Inference: 0.0660 s/iter. Eval: 0.0004 s/iter. Total: 0.0910 s/iter. ETA=0:00:12
[03/27 15:41:36] detectron2.evaluation.evaluator INFO: Inference done 345/421. Dataloading: 0.0236 s/iter. Inference: 0.0667 s/iter. Eval: 0.0004 s/iter. Total: 0.0908 s/iter. ETA=0:00:06
[03/27 15:41:41] detectron2.evaluation.evaluator INFO: Inference done 401/421. Dataloading: 0.0232 s/iter. Inference: 0.0670 s/iter. Eval: 0.0004 s/iter. Total: 0.0907 s/iter. ETA=0:00:01
[03/27 15:41:43] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:38.294812 (0.092055 s / iter per device, on 2 devices)
[03/27 15:41:43] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:27 (0.066636 s / iter per device, on 2 devices)
[03/27 15:48:58] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 15:48:58] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 15:48:58] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 15:48:58] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 15:48:58] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 15:48:58] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 15:48:58] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 15:49:04] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0180 s/iter. Inference: 0.0647 s/iter. Eval: 0.0003 s/iter. Total: 0.0830 s/iter. ETA=0:00:34
[03/27 15:49:10] detectron2.evaluation.evaluator INFO: Inference done 58/421. Dataloading: 0.0285 s/iter. Inference: 0.0758 s/iter. Eval: 0.0003 s/iter. Total: 0.1048 s/iter. ETA=0:00:38
[03/27 15:49:15] detectron2.evaluation.evaluator INFO: Inference done 114/421. Dataloading: 0.0225 s/iter. Inference: 0.0740 s/iter. Eval: 0.0003 s/iter. Total: 0.0970 s/iter. ETA=0:00:29
[03/27 15:49:20] detectron2.evaluation.evaluator INFO: Inference done 174/421. Dataloading: 0.0217 s/iter. Inference: 0.0702 s/iter. Eval: 0.0003 s/iter. Total: 0.0923 s/iter. ETA=0:00:22
[03/27 15:49:25] detectron2.evaluation.evaluator INFO: Inference done 232/421. Dataloading: 0.0211 s/iter. Inference: 0.0696 s/iter. Eval: 0.0004 s/iter. Total: 0.0911 s/iter. ETA=0:00:17
[03/27 15:49:30] detectron2.evaluation.evaluator INFO: Inference done 289/421. Dataloading: 0.0214 s/iter. Inference: 0.0689 s/iter. Eval: 0.0004 s/iter. Total: 0.0907 s/iter. ETA=0:00:11
[03/27 15:49:35] detectron2.evaluation.evaluator INFO: Inference done 348/421. Dataloading: 0.0217 s/iter. Inference: 0.0677 s/iter. Eval: 0.0004 s/iter. Total: 0.0899 s/iter. ETA=0:00:06
[03/27 15:49:40] detectron2.evaluation.evaluator INFO: Inference done 402/421. Dataloading: 0.0223 s/iter. Inference: 0.0676 s/iter. Eval: 0.0004 s/iter. Total: 0.0904 s/iter. ETA=0:00:01
[03/27 15:49:42] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:37.809238 (0.090888 s / iter per device, on 2 devices)
[03/27 15:49:42] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.067572 s / iter per device, on 2 devices)
[03/27 15:56:56] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 15:56:56] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 15:56:56] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 15:56:56] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 15:56:56] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 15:56:56] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 15:56:56] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 15:57:04] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0127 s/iter. Inference: 0.0664 s/iter. Eval: 0.0022 s/iter. Total: 0.0812 s/iter. ETA=0:00:33
[03/27 15:57:09] detectron2.evaluation.evaluator INFO: Inference done 68/421. Dataloading: 0.0228 s/iter. Inference: 0.0642 s/iter. Eval: 0.0006 s/iter. Total: 0.0876 s/iter. ETA=0:00:30
[03/27 15:57:15] detectron2.evaluation.evaluator INFO: Inference done 126/421. Dataloading: 0.0185 s/iter. Inference: 0.0683 s/iter. Eval: 0.0004 s/iter. Total: 0.0873 s/iter. ETA=0:00:25
[03/27 15:57:20] detectron2.evaluation.evaluator INFO: Inference done 177/421. Dataloading: 0.0217 s/iter. Inference: 0.0688 s/iter. Eval: 0.0004 s/iter. Total: 0.0910 s/iter. ETA=0:00:22
[03/27 15:57:25] detectron2.evaluation.evaluator INFO: Inference done 228/421. Dataloading: 0.0235 s/iter. Inference: 0.0689 s/iter. Eval: 0.0004 s/iter. Total: 0.0928 s/iter. ETA=0:00:17
[03/27 15:57:30] detectron2.evaluation.evaluator INFO: Inference done 286/421. Dataloading: 0.0225 s/iter. Inference: 0.0686 s/iter. Eval: 0.0004 s/iter. Total: 0.0916 s/iter. ETA=0:00:12
[03/27 15:57:35] detectron2.evaluation.evaluator INFO: Inference done 344/421. Dataloading: 0.0218 s/iter. Inference: 0.0684 s/iter. Eval: 0.0004 s/iter. Total: 0.0907 s/iter. ETA=0:00:06
[03/27 15:57:40] detectron2.evaluation.evaluator INFO: Inference done 400/421. Dataloading: 0.0216 s/iter. Inference: 0.0686 s/iter. Eval: 0.0004 s/iter. Total: 0.0907 s/iter. ETA=0:00:01
[03/27 15:57:42] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:37.977322 (0.091292 s / iter per device, on 2 devices)
[03/27 15:57:42] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.068388 s / iter per device, on 2 devices)
[03/27 16:04:53] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 16:04:53] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 16:04:53] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 16:04:53] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 16:04:53] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 16:04:53] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 16:04:53] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 16:04:59] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0230 s/iter. Inference: 0.0576 s/iter. Eval: 0.0003 s/iter. Total: 0.0810 s/iter. ETA=0:00:33
[03/27 16:05:04] detectron2.evaluation.evaluator INFO: Inference done 69/421. Dataloading: 0.0174 s/iter. Inference: 0.0683 s/iter. Eval: 0.0006 s/iter. Total: 0.0864 s/iter. ETA=0:00:30
[03/27 16:05:09] detectron2.evaluation.evaluator INFO: Inference done 125/421. Dataloading: 0.0166 s/iter. Inference: 0.0705 s/iter. Eval: 0.0008 s/iter. Total: 0.0880 s/iter. ETA=0:00:26
[03/27 16:05:15] detectron2.evaluation.evaluator INFO: Inference done 179/421. Dataloading: 0.0205 s/iter. Inference: 0.0685 s/iter. Eval: 0.0007 s/iter. Total: 0.0898 s/iter. ETA=0:00:21
[03/27 16:05:20] detectron2.evaluation.evaluator INFO: Inference done 234/421. Dataloading: 0.0212 s/iter. Inference: 0.0680 s/iter. Eval: 0.0008 s/iter. Total: 0.0901 s/iter. ETA=0:00:16
[03/27 16:05:25] detectron2.evaluation.evaluator INFO: Inference done 294/421. Dataloading: 0.0196 s/iter. Inference: 0.0684 s/iter. Eval: 0.0007 s/iter. Total: 0.0889 s/iter. ETA=0:00:11
[03/27 16:05:30] detectron2.evaluation.evaluator INFO: Inference done 352/421. Dataloading: 0.0197 s/iter. Inference: 0.0680 s/iter. Eval: 0.0007 s/iter. Total: 0.0885 s/iter. ETA=0:00:06
[03/27 16:05:35] detectron2.evaluation.evaluator INFO: Inference done 404/421. Dataloading: 0.0207 s/iter. Inference: 0.0683 s/iter. Eval: 0.0006 s/iter. Total: 0.0898 s/iter. ETA=0:00:01
[03/27 16:05:37] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:38.528984 (0.092618 s / iter per device, on 2 devices)
[03/27 16:05:37] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.068240 s / iter per device, on 2 devices)
[03/27 16:12:50] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 16:12:50] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 16:12:50] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 16:12:50] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 16:12:50] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 16:12:50] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 16:12:50] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 16:13:00] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0072 s/iter. Inference: 0.0629 s/iter. Eval: 0.0003 s/iter. Total: 0.0704 s/iter. ETA=0:00:28
[03/27 16:13:05] detectron2.evaluation.evaluator INFO: Inference done 67/421. Dataloading: 0.0182 s/iter. Inference: 0.0697 s/iter. Eval: 0.0005 s/iter. Total: 0.0886 s/iter. ETA=0:00:31
[03/27 16:13:10] detectron2.evaluation.evaluator INFO: Inference done 126/421. Dataloading: 0.0173 s/iter. Inference: 0.0691 s/iter. Eval: 0.0006 s/iter. Total: 0.0871 s/iter. ETA=0:00:25
[03/27 16:13:15] detectron2.evaluation.evaluator INFO: Inference done 184/421. Dataloading: 0.0189 s/iter. Inference: 0.0677 s/iter. Eval: 0.0005 s/iter. Total: 0.0873 s/iter. ETA=0:00:20
[03/27 16:13:20] detectron2.evaluation.evaluator INFO: Inference done 240/421. Dataloading: 0.0187 s/iter. Inference: 0.0683 s/iter. Eval: 0.0006 s/iter. Total: 0.0878 s/iter. ETA=0:00:15
[03/27 16:13:25] detectron2.evaluation.evaluator INFO: Inference done 297/421. Dataloading: 0.0186 s/iter. Inference: 0.0688 s/iter. Eval: 0.0006 s/iter. Total: 0.0881 s/iter. ETA=0:00:10
[03/27 16:13:30] detectron2.evaluation.evaluator INFO: Inference done 354/421. Dataloading: 0.0185 s/iter. Inference: 0.0691 s/iter. Eval: 0.0005 s/iter. Total: 0.0883 s/iter. ETA=0:00:05
[03/27 16:13:35] detectron2.evaluation.evaluator INFO: Inference done 412/421. Dataloading: 0.0193 s/iter. Inference: 0.0682 s/iter. Eval: 0.0005 s/iter. Total: 0.0881 s/iter. ETA=0:00:00
[03/27 16:13:36] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:37.052156 (0.089068 s / iter per device, on 2 devices)
[03/27 16:13:36] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.068416 s / iter per device, on 2 devices)
[03/27 16:20:50] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 16:20:50] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 16:20:50] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 16:20:50] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 16:20:50] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 16:20:50] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 16:20:50] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 16:20:56] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0090 s/iter. Inference: 0.0568 s/iter. Eval: 0.0003 s/iter. Total: 0.0661 s/iter. ETA=0:00:27
[03/27 16:21:01] detectron2.evaluation.evaluator INFO: Inference done 66/421. Dataloading: 0.0215 s/iter. Inference: 0.0667 s/iter. Eval: 0.0003 s/iter. Total: 0.0886 s/iter. ETA=0:00:31
[03/27 16:21:06] detectron2.evaluation.evaluator INFO: Inference done 125/421. Dataloading: 0.0191 s/iter. Inference: 0.0676 s/iter. Eval: 0.0005 s/iter. Total: 0.0873 s/iter. ETA=0:00:25
[03/27 16:21:11] detectron2.evaluation.evaluator INFO: Inference done 186/421. Dataloading: 0.0186 s/iter. Inference: 0.0664 s/iter. Eval: 0.0004 s/iter. Total: 0.0856 s/iter. ETA=0:00:20
[03/27 16:21:17] detectron2.evaluation.evaluator INFO: Inference done 241/421. Dataloading: 0.0203 s/iter. Inference: 0.0666 s/iter. Eval: 0.0004 s/iter. Total: 0.0874 s/iter. ETA=0:00:15
[03/27 16:21:22] detectron2.evaluation.evaluator INFO: Inference done 297/421. Dataloading: 0.0201 s/iter. Inference: 0.0672 s/iter. Eval: 0.0004 s/iter. Total: 0.0879 s/iter. ETA=0:00:10
[03/27 16:21:27] detectron2.evaluation.evaluator INFO: Inference done 348/421. Dataloading: 0.0209 s/iter. Inference: 0.0679 s/iter. Eval: 0.0004 s/iter. Total: 0.0894 s/iter. ETA=0:00:06
[03/27 16:21:32] detectron2.evaluation.evaluator INFO: Inference done 405/421. Dataloading: 0.0209 s/iter. Inference: 0.0679 s/iter. Eval: 0.0004 s/iter. Total: 0.0894 s/iter. ETA=0:00:01
[03/27 16:21:33] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:37.459853 (0.090048 s / iter per device, on 2 devices)
[03/27 16:21:33] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.067785 s / iter per device, on 2 devices)
[03/27 16:28:47] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 16:28:47] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 16:28:47] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 16:28:47] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 16:28:47] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 16:28:47] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 16:28:47] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 16:28:56] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0116 s/iter. Inference: 0.0631 s/iter. Eval: 0.0003 s/iter. Total: 0.0750 s/iter. ETA=0:00:30
[03/27 16:29:02] detectron2.evaluation.evaluator INFO: Inference done 66/421. Dataloading: 0.0250 s/iter. Inference: 0.0648 s/iter. Eval: 0.0004 s/iter. Total: 0.0902 s/iter. ETA=0:00:32
[03/27 16:29:07] detectron2.evaluation.evaluator INFO: Inference done 120/421. Dataloading: 0.0246 s/iter. Inference: 0.0665 s/iter. Eval: 0.0004 s/iter. Total: 0.0917 s/iter. ETA=0:00:27
[03/27 16:29:12] detectron2.evaluation.evaluator INFO: Inference done 178/421. Dataloading: 0.0238 s/iter. Inference: 0.0662 s/iter. Eval: 0.0004 s/iter. Total: 0.0905 s/iter. ETA=0:00:21
[03/27 16:29:17] detectron2.evaluation.evaluator INFO: Inference done 228/421. Dataloading: 0.0244 s/iter. Inference: 0.0681 s/iter. Eval: 0.0005 s/iter. Total: 0.0930 s/iter. ETA=0:00:17
[03/27 16:29:22] detectron2.evaluation.evaluator INFO: Inference done 285/421. Dataloading: 0.0232 s/iter. Inference: 0.0685 s/iter. Eval: 0.0005 s/iter. Total: 0.0922 s/iter. ETA=0:00:12
[03/27 16:29:27] detectron2.evaluation.evaluator INFO: Inference done 342/421. Dataloading: 0.0225 s/iter. Inference: 0.0686 s/iter. Eval: 0.0005 s/iter. Total: 0.0917 s/iter. ETA=0:00:07
[03/27 16:29:32] detectron2.evaluation.evaluator INFO: Inference done 400/421. Dataloading: 0.0218 s/iter. Inference: 0.0685 s/iter. Eval: 0.0005 s/iter. Total: 0.0909 s/iter. ETA=0:00:01
[03/27 16:29:34] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:38.083569 (0.091547 s / iter per device, on 2 devices)
[03/27 16:29:34] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.068355 s / iter per device, on 2 devices)
[03/27 16:36:51] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 16:36:51] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 16:36:51] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 16:36:51] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 16:36:51] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 16:36:51] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 16:36:51] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 16:36:57] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0057 s/iter. Inference: 0.0715 s/iter. Eval: 0.0003 s/iter. Total: 0.0775 s/iter. ETA=0:00:31
[03/27 16:37:02] detectron2.evaluation.evaluator INFO: Inference done 69/421. Dataloading: 0.0218 s/iter. Inference: 0.0642 s/iter. Eval: 0.0003 s/iter. Total: 0.0864 s/iter. ETA=0:00:30
[03/27 16:37:07] detectron2.evaluation.evaluator INFO: Inference done 129/421. Dataloading: 0.0204 s/iter. Inference: 0.0646 s/iter. Eval: 0.0003 s/iter. Total: 0.0854 s/iter. ETA=0:00:24
[03/27 16:37:13] detectron2.evaluation.evaluator INFO: Inference done 188/421. Dataloading: 0.0208 s/iter. Inference: 0.0648 s/iter. Eval: 0.0003 s/iter. Total: 0.0860 s/iter. ETA=0:00:20
[03/27 16:37:18] detectron2.evaluation.evaluator INFO: Inference done 247/421. Dataloading: 0.0207 s/iter. Inference: 0.0650 s/iter. Eval: 0.0003 s/iter. Total: 0.0861 s/iter. ETA=0:00:14
[03/27 16:37:23] detectron2.evaluation.evaluator INFO: Inference done 307/421. Dataloading: 0.0200 s/iter. Inference: 0.0654 s/iter. Eval: 0.0003 s/iter. Total: 0.0858 s/iter. ETA=0:00:09
[03/27 16:37:28] detectron2.evaluation.evaluator INFO: Inference done 367/421. Dataloading: 0.0199 s/iter. Inference: 0.0653 s/iter. Eval: 0.0003 s/iter. Total: 0.0856 s/iter. ETA=0:00:04
[03/27 16:37:33] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:36.522413 (0.087794 s / iter per device, on 2 devices)
[03/27 16:37:33] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:27 (0.065035 s / iter per device, on 2 devices)
[03/27 16:44:57] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 16:44:57] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 16:44:57] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 16:44:57] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 16:44:57] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 16:44:57] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 16:44:57] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 16:45:06] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0124 s/iter. Inference: 0.0687 s/iter. Eval: 0.0003 s/iter. Total: 0.0814 s/iter. ETA=0:00:33
[03/27 16:45:11] detectron2.evaluation.evaluator INFO: Inference done 67/421. Dataloading: 0.0145 s/iter. Inference: 0.0742 s/iter. Eval: 0.0004 s/iter. Total: 0.0891 s/iter. ETA=0:00:31
[03/27 16:45:16] detectron2.evaluation.evaluator INFO: Inference done 122/421. Dataloading: 0.0166 s/iter. Inference: 0.0731 s/iter. Eval: 0.0005 s/iter. Total: 0.0903 s/iter. ETA=0:00:27
[03/27 16:45:21] detectron2.evaluation.evaluator INFO: Inference done 176/421. Dataloading: 0.0191 s/iter. Inference: 0.0714 s/iter. Eval: 0.0005 s/iter. Total: 0.0912 s/iter. ETA=0:00:22
[03/27 16:45:26] detectron2.evaluation.evaluator INFO: Inference done 235/421. Dataloading: 0.0179 s/iter. Inference: 0.0712 s/iter. Eval: 0.0005 s/iter. Total: 0.0898 s/iter. ETA=0:00:16
[03/27 16:45:32] detectron2.evaluation.evaluator INFO: Inference done 296/421. Dataloading: 0.0175 s/iter. Inference: 0.0703 s/iter. Eval: 0.0005 s/iter. Total: 0.0884 s/iter. ETA=0:00:11
[03/27 16:45:37] detectron2.evaluation.evaluator INFO: Inference done 349/421. Dataloading: 0.0186 s/iter. Inference: 0.0702 s/iter. Eval: 0.0005 s/iter. Total: 0.0894 s/iter. ETA=0:00:06
[03/27 16:45:42] detectron2.evaluation.evaluator INFO: Inference done 407/421. Dataloading: 0.0180 s/iter. Inference: 0.0707 s/iter. Eval: 0.0006 s/iter. Total: 0.0894 s/iter. ETA=0:00:01
[03/27 16:45:43] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:37.458958 (0.090046 s / iter per device, on 2 devices)
[03/27 16:45:43] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:29 (0.070447 s / iter per device, on 2 devices)
[03/27 16:53:04] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 16:53:04] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 16:53:04] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 16:53:04] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 16:53:04] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 16:53:04] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 16:53:04] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 16:53:10] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0194 s/iter. Inference: 0.0670 s/iter. Eval: 0.0003 s/iter. Total: 0.0868 s/iter. ETA=0:00:35
[03/27 16:53:15] detectron2.evaluation.evaluator INFO: Inference done 60/421. Dataloading: 0.0274 s/iter. Inference: 0.0730 s/iter. Eval: 0.0007 s/iter. Total: 0.1013 s/iter. ETA=0:00:36
[03/27 16:53:20] detectron2.evaluation.evaluator INFO: Inference done 118/421. Dataloading: 0.0233 s/iter. Inference: 0.0696 s/iter. Eval: 0.0006 s/iter. Total: 0.0936 s/iter. ETA=0:00:28
[03/27 16:53:25] detectron2.evaluation.evaluator INFO: Inference done 172/421. Dataloading: 0.0217 s/iter. Inference: 0.0709 s/iter. Eval: 0.0006 s/iter. Total: 0.0933 s/iter. ETA=0:00:23
[03/27 16:53:31] detectron2.evaluation.evaluator INFO: Inference done 227/421. Dataloading: 0.0206 s/iter. Inference: 0.0718 s/iter. Eval: 0.0007 s/iter. Total: 0.0932 s/iter. ETA=0:00:18
[03/27 16:53:36] detectron2.evaluation.evaluator INFO: Inference done 280/421. Dataloading: 0.0219 s/iter. Inference: 0.0709 s/iter. Eval: 0.0006 s/iter. Total: 0.0935 s/iter. ETA=0:00:13
[03/27 16:53:41] detectron2.evaluation.evaluator INFO: Inference done 332/421. Dataloading: 0.0225 s/iter. Inference: 0.0708 s/iter. Eval: 0.0006 s/iter. Total: 0.0940 s/iter. ETA=0:00:08
[03/27 16:53:46] detectron2.evaluation.evaluator INFO: Inference done 388/421. Dataloading: 0.0220 s/iter. Inference: 0.0707 s/iter. Eval: 0.0006 s/iter. Total: 0.0934 s/iter. ETA=0:00:03
[03/27 16:53:49] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:39.401613 (0.094715 s / iter per device, on 2 devices)
[03/27 16:53:49] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:29 (0.070644 s / iter per device, on 2 devices)
[03/27 17:01:08] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 17:01:08] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 17:01:08] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 17:01:08] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 17:01:08] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 17:01:08] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 17:01:08] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 17:01:18] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0300 s/iter. Inference: 0.0618 s/iter. Eval: 0.0003 s/iter. Total: 0.0921 s/iter. ETA=0:00:37
[03/27 17:01:23] detectron2.evaluation.evaluator INFO: Inference done 69/421. Dataloading: 0.0187 s/iter. Inference: 0.0682 s/iter. Eval: 0.0004 s/iter. Total: 0.0873 s/iter. ETA=0:00:30
[03/27 17:01:28] detectron2.evaluation.evaluator INFO: Inference done 127/421. Dataloading: 0.0198 s/iter. Inference: 0.0668 s/iter. Eval: 0.0004 s/iter. Total: 0.0871 s/iter. ETA=0:00:25
[03/27 17:01:33] detectron2.evaluation.evaluator INFO: Inference done 180/421. Dataloading: 0.0207 s/iter. Inference: 0.0682 s/iter. Eval: 0.0005 s/iter. Total: 0.0894 s/iter. ETA=0:00:21
[03/27 17:01:38] detectron2.evaluation.evaluator INFO: Inference done 231/421. Dataloading: 0.0213 s/iter. Inference: 0.0698 s/iter. Eval: 0.0004 s/iter. Total: 0.0917 s/iter. ETA=0:00:17
[03/27 17:01:43] detectron2.evaluation.evaluator INFO: Inference done 287/421. Dataloading: 0.0218 s/iter. Inference: 0.0692 s/iter. Eval: 0.0004 s/iter. Total: 0.0914 s/iter. ETA=0:00:12
[03/27 17:01:48] detectron2.evaluation.evaluator INFO: Inference done 337/421. Dataloading: 0.0230 s/iter. Inference: 0.0696 s/iter. Eval: 0.0004 s/iter. Total: 0.0931 s/iter. ETA=0:00:07
[03/27 17:01:53] detectron2.evaluation.evaluator INFO: Inference done 392/421. Dataloading: 0.0231 s/iter. Inference: 0.0693 s/iter. Eval: 0.0004 s/iter. Total: 0.0928 s/iter. ETA=0:00:02
[03/27 17:01:56] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:38.913542 (0.093542 s / iter per device, on 2 devices)
[03/27 17:01:56] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.068943 s / iter per device, on 2 devices)
[03/27 17:09:19] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 17:09:19] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 17:09:19] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 17:09:19] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 17:09:19] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 17:09:19] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 17:09:19] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 17:09:30] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0098 s/iter. Inference: 0.0675 s/iter. Eval: 0.0003 s/iter. Total: 0.0776 s/iter. ETA=0:00:31
[03/27 17:09:35] detectron2.evaluation.evaluator INFO: Inference done 63/421. Dataloading: 0.0232 s/iter. Inference: 0.0712 s/iter. Eval: 0.0004 s/iter. Total: 0.0948 s/iter. ETA=0:00:33
[03/27 17:09:40] detectron2.evaluation.evaluator INFO: Inference done 120/421. Dataloading: 0.0213 s/iter. Inference: 0.0704 s/iter. Eval: 0.0004 s/iter. Total: 0.0922 s/iter. ETA=0:00:27
[03/27 17:09:45] detectron2.evaluation.evaluator INFO: Inference done 175/421. Dataloading: 0.0209 s/iter. Inference: 0.0706 s/iter. Eval: 0.0004 s/iter. Total: 0.0920 s/iter. ETA=0:00:22
[03/27 17:09:50] detectron2.evaluation.evaluator INFO: Inference done 231/421. Dataloading: 0.0212 s/iter. Inference: 0.0698 s/iter. Eval: 0.0004 s/iter. Total: 0.0915 s/iter. ETA=0:00:17
[03/27 17:09:55] detectron2.evaluation.evaluator INFO: Inference done 291/421. Dataloading: 0.0204 s/iter. Inference: 0.0692 s/iter. Eval: 0.0004 s/iter. Total: 0.0901 s/iter. ETA=0:00:11
[03/27 17:10:00] detectron2.evaluation.evaluator INFO: Inference done 348/421. Dataloading: 0.0195 s/iter. Inference: 0.0697 s/iter. Eval: 0.0004 s/iter. Total: 0.0897 s/iter. ETA=0:00:06
[03/27 17:10:05] detectron2.evaluation.evaluator INFO: Inference done 404/421. Dataloading: 0.0200 s/iter. Inference: 0.0691 s/iter. Eval: 0.0005 s/iter. Total: 0.0897 s/iter. ETA=0:00:01
[03/27 17:10:07] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:38.364140 (0.092221 s / iter per device, on 2 devices)
[03/27 17:10:07] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.069048 s / iter per device, on 2 devices)
[03/27 17:17:28] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 17:17:28] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 17:17:28] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 17:17:28] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 17:17:28] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 17:17:28] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 17:17:28] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 17:17:39] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0258 s/iter. Inference: 0.0763 s/iter. Eval: 0.0003 s/iter. Total: 0.1024 s/iter. ETA=0:00:41
[03/27 17:17:44] detectron2.evaluation.evaluator INFO: Inference done 61/421. Dataloading: 0.0240 s/iter. Inference: 0.0762 s/iter. Eval: 0.0005 s/iter. Total: 0.1008 s/iter. ETA=0:00:36
[03/27 17:17:49] detectron2.evaluation.evaluator INFO: Inference done 114/421. Dataloading: 0.0241 s/iter. Inference: 0.0730 s/iter. Eval: 0.0005 s/iter. Total: 0.0977 s/iter. ETA=0:00:29
[03/27 17:17:54] detectron2.evaluation.evaluator INFO: Inference done 175/421. Dataloading: 0.0212 s/iter. Inference: 0.0707 s/iter. Eval: 0.0004 s/iter. Total: 0.0924 s/iter. ETA=0:00:22
[03/27 17:17:59] detectron2.evaluation.evaluator INFO: Inference done 234/421. Dataloading: 0.0200 s/iter. Inference: 0.0700 s/iter. Eval: 0.0005 s/iter. Total: 0.0906 s/iter. ETA=0:00:16
[03/27 17:18:04] detectron2.evaluation.evaluator INFO: Inference done 294/421. Dataloading: 0.0194 s/iter. Inference: 0.0694 s/iter. Eval: 0.0005 s/iter. Total: 0.0894 s/iter. ETA=0:00:11
[03/27 17:18:09] detectron2.evaluation.evaluator INFO: Inference done 355/421. Dataloading: 0.0188 s/iter. Inference: 0.0690 s/iter. Eval: 0.0005 s/iter. Total: 0.0884 s/iter. ETA=0:00:05
[03/27 17:18:14] detectron2.evaluation.evaluator INFO: Inference done 413/421. Dataloading: 0.0188 s/iter. Inference: 0.0688 s/iter. Eval: 0.0005 s/iter. Total: 0.0881 s/iter. ETA=0:00:00
[03/27 17:18:15] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:37.088883 (0.089156 s / iter per device, on 2 devices)
[03/27 17:18:15] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.068718 s / iter per device, on 2 devices)
[03/27 17:25:41] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 17:25:41] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 17:25:41] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 17:25:41] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 17:25:41] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 17:25:41] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 17:25:41] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 17:25:48] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0150 s/iter. Inference: 0.0914 s/iter. Eval: 0.0004 s/iter. Total: 0.1068 s/iter. ETA=0:00:43
[03/27 17:25:53] detectron2.evaluation.evaluator INFO: Inference done 66/421. Dataloading: 0.0179 s/iter. Inference: 0.0749 s/iter. Eval: 0.0004 s/iter. Total: 0.0933 s/iter. ETA=0:00:33
[03/27 17:25:58] detectron2.evaluation.evaluator INFO: Inference done 120/421. Dataloading: 0.0178 s/iter. Inference: 0.0748 s/iter. Eval: 0.0005 s/iter. Total: 0.0932 s/iter. ETA=0:00:28
[03/27 17:26:03] detectron2.evaluation.evaluator INFO: Inference done 177/421. Dataloading: 0.0165 s/iter. Inference: 0.0746 s/iter. Eval: 0.0004 s/iter. Total: 0.0916 s/iter. ETA=0:00:22
[03/27 17:26:08] detectron2.evaluation.evaluator INFO: Inference done 232/421. Dataloading: 0.0169 s/iter. Inference: 0.0740 s/iter. Eval: 0.0005 s/iter. Total: 0.0914 s/iter. ETA=0:00:17
[03/27 17:26:13] detectron2.evaluation.evaluator INFO: Inference done 292/421. Dataloading: 0.0164 s/iter. Inference: 0.0728 s/iter. Eval: 0.0005 s/iter. Total: 0.0898 s/iter. ETA=0:00:11
[03/27 17:26:18] detectron2.evaluation.evaluator INFO: Inference done 348/421. Dataloading: 0.0170 s/iter. Inference: 0.0725 s/iter. Eval: 0.0005 s/iter. Total: 0.0900 s/iter. ETA=0:00:06
[03/27 17:26:23] detectron2.evaluation.evaluator INFO: Inference done 401/421. Dataloading: 0.0175 s/iter. Inference: 0.0727 s/iter. Eval: 0.0005 s/iter. Total: 0.0907 s/iter. ETA=0:00:01
[03/27 17:26:25] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:38.120026 (0.091635 s / iter per device, on 2 devices)
[03/27 17:26:25] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:30 (0.072203 s / iter per device, on 2 devices)
[03/27 17:33:53] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 17:33:53] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 17:33:53] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 17:33:53] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 17:33:53] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 17:33:53] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 17:33:53] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 17:34:03] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0214 s/iter. Inference: 0.0688 s/iter. Eval: 0.0004 s/iter. Total: 0.0905 s/iter. ETA=0:00:37
[03/27 17:34:08] detectron2.evaluation.evaluator INFO: Inference done 67/421. Dataloading: 0.0222 s/iter. Inference: 0.0670 s/iter. Eval: 0.0005 s/iter. Total: 0.0899 s/iter. ETA=0:00:31
[03/27 17:34:13] detectron2.evaluation.evaluator INFO: Inference done 123/421. Dataloading: 0.0212 s/iter. Inference: 0.0684 s/iter. Eval: 0.0004 s/iter. Total: 0.0902 s/iter. ETA=0:00:26
[03/27 17:34:18] detectron2.evaluation.evaluator INFO: Inference done 174/421. Dataloading: 0.0233 s/iter. Inference: 0.0686 s/iter. Eval: 0.0005 s/iter. Total: 0.0927 s/iter. ETA=0:00:22
[03/27 17:34:23] detectron2.evaluation.evaluator INFO: Inference done 232/421. Dataloading: 0.0222 s/iter. Inference: 0.0684 s/iter. Eval: 0.0004 s/iter. Total: 0.0913 s/iter. ETA=0:00:17
[03/27 17:34:28] detectron2.evaluation.evaluator INFO: Inference done 285/421. Dataloading: 0.0231 s/iter. Inference: 0.0682 s/iter. Eval: 0.0004 s/iter. Total: 0.0919 s/iter. ETA=0:00:12
[03/27 17:34:33] detectron2.evaluation.evaluator INFO: Inference done 342/421. Dataloading: 0.0227 s/iter. Inference: 0.0682 s/iter. Eval: 0.0004 s/iter. Total: 0.0914 s/iter. ETA=0:00:07
[03/27 17:34:38] detectron2.evaluation.evaluator INFO: Inference done 396/421. Dataloading: 0.0228 s/iter. Inference: 0.0682 s/iter. Eval: 0.0004 s/iter. Total: 0.0916 s/iter. ETA=0:00:02
[03/27 17:34:40] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:38.422213 (0.092361 s / iter per device, on 2 devices)
[03/27 17:34:40] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.067963 s / iter per device, on 2 devices)
[03/27 17:42:09] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 17:42:09] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 17:42:09] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 17:42:09] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 17:42:09] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 17:42:09] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 17:42:09] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 17:42:15] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0107 s/iter. Inference: 0.0812 s/iter. Eval: 0.0003 s/iter. Total: 0.0921 s/iter. ETA=0:00:37
[03/27 17:42:20] detectron2.evaluation.evaluator INFO: Inference done 67/421. Dataloading: 0.0175 s/iter. Inference: 0.0720 s/iter. Eval: 0.0003 s/iter. Total: 0.0900 s/iter. ETA=0:00:31
[03/27 17:42:25] detectron2.evaluation.evaluator INFO: Inference done 124/421. Dataloading: 0.0175 s/iter. Inference: 0.0712 s/iter. Eval: 0.0003 s/iter. Total: 0.0891 s/iter. ETA=0:00:26
[03/27 17:42:30] detectron2.evaluation.evaluator INFO: Inference done 179/421. Dataloading: 0.0197 s/iter. Inference: 0.0698 s/iter. Eval: 0.0003 s/iter. Total: 0.0899 s/iter. ETA=0:00:21
[03/27 17:42:35] detectron2.evaluation.evaluator INFO: Inference done 237/421. Dataloading: 0.0200 s/iter. Inference: 0.0686 s/iter. Eval: 0.0003 s/iter. Total: 0.0891 s/iter. ETA=0:00:16
[03/27 17:42:40] detectron2.evaluation.evaluator INFO: Inference done 293/421. Dataloading: 0.0201 s/iter. Inference: 0.0687 s/iter. Eval: 0.0003 s/iter. Total: 0.0893 s/iter. ETA=0:00:11
[03/27 17:42:45] detectron2.evaluation.evaluator INFO: Inference done 349/421. Dataloading: 0.0199 s/iter. Inference: 0.0691 s/iter. Eval: 0.0003 s/iter. Total: 0.0895 s/iter. ETA=0:00:06
[03/27 17:42:51] detectron2.evaluation.evaluator INFO: Inference done 403/421. Dataloading: 0.0201 s/iter. Inference: 0.0696 s/iter. Eval: 0.0003 s/iter. Total: 0.0901 s/iter. ETA=0:00:01
[03/27 17:42:52] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:37.760357 (0.090770 s / iter per device, on 2 devices)
[03/27 17:42:52] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.069551 s / iter per device, on 2 devices)
[03/27 17:50:18] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 17:50:18] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 17:50:18] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 17:50:18] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 17:50:18] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 17:50:18] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 17:50:19] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 17:50:28] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0178 s/iter. Inference: 0.0549 s/iter. Eval: 0.0003 s/iter. Total: 0.0730 s/iter. ETA=0:00:29
[03/27 17:50:33] detectron2.evaluation.evaluator INFO: Inference done 65/421. Dataloading: 0.0243 s/iter. Inference: 0.0659 s/iter. Eval: 0.0003 s/iter. Total: 0.0906 s/iter. ETA=0:00:32
[03/27 17:50:38] detectron2.evaluation.evaluator INFO: Inference done 120/421. Dataloading: 0.0226 s/iter. Inference: 0.0677 s/iter. Eval: 0.0003 s/iter. Total: 0.0910 s/iter. ETA=0:00:27
[03/27 17:50:43] detectron2.evaluation.evaluator INFO: Inference done 180/421. Dataloading: 0.0214 s/iter. Inference: 0.0664 s/iter. Eval: 0.0004 s/iter. Total: 0.0885 s/iter. ETA=0:00:21
[03/27 17:50:48] detectron2.evaluation.evaluator INFO: Inference done 236/421. Dataloading: 0.0208 s/iter. Inference: 0.0674 s/iter. Eval: 0.0004 s/iter. Total: 0.0889 s/iter. ETA=0:00:16
[03/27 17:50:54] detectron2.evaluation.evaluator INFO: Inference done 298/421. Dataloading: 0.0199 s/iter. Inference: 0.0671 s/iter. Eval: 0.0005 s/iter. Total: 0.0876 s/iter. ETA=0:00:10
[03/27 17:50:59] detectron2.evaluation.evaluator INFO: Inference done 350/421. Dataloading: 0.0212 s/iter. Inference: 0.0674 s/iter. Eval: 0.0005 s/iter. Total: 0.0893 s/iter. ETA=0:00:06
[03/27 17:51:04] detectron2.evaluation.evaluator INFO: Inference done 404/421. Dataloading: 0.0215 s/iter. Inference: 0.0677 s/iter. Eval: 0.0005 s/iter. Total: 0.0898 s/iter. ETA=0:00:01
[03/27 17:51:06] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:37.993678 (0.091331 s / iter per device, on 2 devices)
[03/27 17:51:06] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.067760 s / iter per device, on 2 devices)
[03/27 17:58:29] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 17:58:29] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 17:58:29] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 17:58:29] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 17:58:29] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 17:58:29] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 17:58:29] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 17:58:35] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0083 s/iter. Inference: 0.0623 s/iter. Eval: 0.0003 s/iter. Total: 0.0709 s/iter. ETA=0:00:29
[03/27 17:58:41] detectron2.evaluation.evaluator INFO: Inference done 67/421. Dataloading: 0.0228 s/iter. Inference: 0.0662 s/iter. Eval: 0.0003 s/iter. Total: 0.0894 s/iter. ETA=0:00:31
[03/27 17:58:46] detectron2.evaluation.evaluator INFO: Inference done 119/421. Dataloading: 0.0239 s/iter. Inference: 0.0681 s/iter. Eval: 0.0004 s/iter. Total: 0.0926 s/iter. ETA=0:00:27
[03/27 17:58:51] detectron2.evaluation.evaluator INFO: Inference done 175/421. Dataloading: 0.0230 s/iter. Inference: 0.0680 s/iter. Eval: 0.0005 s/iter. Total: 0.0916 s/iter. ETA=0:00:22
[03/27 17:58:56] detectron2.evaluation.evaluator INFO: Inference done 233/421. Dataloading: 0.0221 s/iter. Inference: 0.0678 s/iter. Eval: 0.0005 s/iter. Total: 0.0904 s/iter. ETA=0:00:16
[03/27 17:59:01] detectron2.evaluation.evaluator INFO: Inference done 291/421. Dataloading: 0.0218 s/iter. Inference: 0.0673 s/iter. Eval: 0.0005 s/iter. Total: 0.0896 s/iter. ETA=0:00:11
[03/27 17:59:06] detectron2.evaluation.evaluator INFO: Inference done 346/421. Dataloading: 0.0220 s/iter. Inference: 0.0676 s/iter. Eval: 0.0004 s/iter. Total: 0.0901 s/iter. ETA=0:00:06
[03/27 17:59:11] detectron2.evaluation.evaluator INFO: Inference done 404/421. Dataloading: 0.0218 s/iter. Inference: 0.0674 s/iter. Eval: 0.0005 s/iter. Total: 0.0897 s/iter. ETA=0:00:01
[03/27 17:59:13] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:37.701798 (0.090629 s / iter per device, on 2 devices)
[03/27 17:59:13] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.067381 s / iter per device, on 2 devices)
[03/27 18:06:39] detectron2.engine.hooks INFO: Overall training speed: 17998 iterations in 4:25:04 (0.8837 s / it)
[03/27 18:06:39] detectron2.engine.hooks INFO: Total training time: 4:53:28 (0:28:24 on hooks)
[03/27 18:06:39] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/27 18:06:39] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/27 18:06:39] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/27 18:06:39] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/27 18:06:39] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/27 18:06:39] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/27 18:06:39] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/27 18:06:51] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0272 s/iter. Inference: 0.0689 s/iter. Eval: 0.0003 s/iter. Total: 0.0963 s/iter. ETA=0:00:39
[03/27 18:06:56] detectron2.evaluation.evaluator INFO: Inference done 54/421. Dataloading: 0.0353 s/iter. Inference: 0.0806 s/iter. Eval: 0.0003 s/iter. Total: 0.1162 s/iter. ETA=0:00:42
[03/27 18:07:01] detectron2.evaluation.evaluator INFO: Inference done 101/421. Dataloading: 0.0341 s/iter. Inference: 0.0775 s/iter. Eval: 0.0003 s/iter. Total: 0.1121 s/iter. ETA=0:00:35
[03/27 18:07:06] detectron2.evaluation.evaluator INFO: Inference done 147/421. Dataloading: 0.0318 s/iter. Inference: 0.0787 s/iter. Eval: 0.0004 s/iter. Total: 0.1111 s/iter. ETA=0:00:30
[03/27 18:07:12] detectron2.evaluation.evaluator INFO: Inference done 191/421. Dataloading: 0.0341 s/iter. Inference: 0.0771 s/iter. Eval: 0.0005 s/iter. Total: 0.1119 s/iter. ETA=0:00:25
[03/27 18:07:17] detectron2.evaluation.evaluator INFO: Inference done 243/421. Dataloading: 0.0338 s/iter. Inference: 0.0742 s/iter. Eval: 0.0005 s/iter. Total: 0.1086 s/iter. ETA=0:00:19
[03/27 18:07:22] detectron2.evaluation.evaluator INFO: Inference done 287/421. Dataloading: 0.0354 s/iter. Inference: 0.0736 s/iter. Eval: 0.0005 s/iter. Total: 0.1096 s/iter. ETA=0:00:14
[03/27 18:07:27] detectron2.evaluation.evaluator INFO: Inference done 333/421. Dataloading: 0.0365 s/iter. Inference: 0.0725 s/iter. Eval: 0.0004 s/iter. Total: 0.1096 s/iter. ETA=0:00:09
[03/27 18:07:32] detectron2.evaluation.evaluator INFO: Inference done 380/421. Dataloading: 0.0373 s/iter. Inference: 0.0717 s/iter. Eval: 0.0004 s/iter. Total: 0.1095 s/iter. ETA=0:00:04
[03/27 18:07:37] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:46.467172 (0.111700 s / iter per device, on 2 devices)
[03/27 18:07:37] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:29 (0.071959 s / iter per device, on 2 devices)
[03/31 07:39:16] detectron2 INFO: Rank of current process: 1. World size: 2
[03/31 07:39:18] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]
numpy                   1.21.2
detectron2              0.6 @/netapp/l.lemikhova/anaconda3/envs/vos/lib/python3.9/site-packages/detectron2
Compiler                GCC 9.4
CUDA compiler           CUDA 11.4
detectron2 arch flags   6.1
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.2 @/netapp/l.lemikhova/anaconda3/envs/vos/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 NVIDIA GeForce GTX 1080 Ti (arch=6.1)
Driver version          470.82.00
CUDA_HOME               /usr/local/cuda
Pillow                  8.4.0
torchvision             0.11.3 @/netapp/l.lemikhova/anaconda3/envs/vos/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220212
iopath                  0.1.9
cv2                     4.5.5
----------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[03/31 07:39:18] detectron2 INFO: Command line arguments: Namespace(config_file='/netapp/l.lemikhova/projects/VOS/vos/detection/configs/Fruits-Detection/Faster-RCNN/coco_openim/vanilla_from_scratch_7.yaml', resume=False, eval_only=False, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:52933', opts=[], dataset_dir='temp', random_seed=0, inference_config='', test_dataset='', image_corruption_level=0, iou_min=0.1, iou_correct=0.5, min_allowed_score=0.0, savefigdir='./savefig', visualize=0)
[03/31 07:39:18] detectron2 INFO: Contents of args.config_file=/netapp/l.lemikhova/projects/VOS/vos/detection/configs/Fruits-Detection/Faster-RCNN/coco_openim/vanilla_from_scratch_7.yaml:
[38;5;242m# CUDA_VISIBLE_DEVICES=0 python vos/detection/train_net.py --num-gpus 1 --config-file Fruits-Detection/Faster-RCNN/coco_openim/vanilla_from_scratch_8_1.yaml --random-seed 0 --resume[39m
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../../../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGeneralizedRCNN[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;242m# WEIGHTS: "https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl"[39m
[38;5;15m  [39m[38;5;242m# WEIGHTS: "/netapp/l.lemikhova/projects/VOS/vos/detection/data/Faster-RCNN/coco_openim/vanilla_from_scratch_8/random_seed_0/model_final.pth"[39m

[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStandardROIHeads[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(640,[39m[38;5;141m [39m[38;5;141m)[39m[38;5;15m  [39m[38;5;242m# (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m640[39m[38;5;15m  [39m[38;5;242m# 640[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m640[39m[38;5;15m  [39m[38;5;242m# 800[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m('coco_ext_fruits_train',[39m[38;5;141m [39m[38;5;141m'openim_id_fruits_train')[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m('openim_id_fruits_val',[39m[38;5;141m [39m[38;5;141m)[39m
[38;5;15m  [39m[38;5;242m# TEST: ('openim_id_fruits_val', 'coco_ext_fruits_val')[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(6000,[39m[38;5;141m [39m[38;5;141m8000)[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m9000[39m[38;5;15m  [39m[38;5;242m# 17.4 epochs[39m
[38;5;15m  [39m[38;5;242m# MAX_ITER: 200  # 17.4 epochs[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m[38;5;15m  [39m[38;5;242m# Depends on the available memory, 8[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m[38;5;15m  [39m[38;5;242m# 100[39m

[03/31 07:39:20] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=8, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=28, bias=True)
    )
  )
)
[03/31 07:39:20] detectron2.data.datasets.coco INFO: Loaded 3564 images in COCO format from ./data/coco_ext/COCO-Format/train_coco_format.json
[03/31 07:39:20] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/31 07:39:20] detectron2.data.datasets.coco INFO: Loaded 4776 images in COCO format from ./data/openim_id/COCO-Format/train_coco_format.json
[03/31 07:39:20] detectron2.data.build INFO: Removed 0 images with no usable annotations. 8340 images left.
[03/31 07:39:21] detectron2.data.build INFO: Distribution of instances among all 7 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|   banana   | 8790         |   apple    | 7834         |   orange   | 10346        |
| strawberry | 6366         |   tomato   | 4830         |   lemon    | 1334         |
|    pear    | 710          |            |              |            |              |
|   total    | 40210        |            |              |            |              |[0m
[03/31 07:39:21] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=640, sample_style='choice'), RandomFlip()]
[03/31 07:39:21] detectron2.data.build INFO: Using training sampler TrainingSampler
[03/31 07:39:21] detectron2.data.common INFO: Serializing 8340 elements to byte tensors and concatenating them all ...
[03/31 07:39:21] detectron2.data.common INFO: Serialized dataset takes 4.04 MiB
[03/31 07:39:21] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[03/31 07:39:21] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[03/31 07:39:21] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[03/31 07:39:21] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[03/31 07:39:21] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[03/31 07:39:21] detectron2.engine.train_loop INFO: Starting training from iteration 0
[03/31 07:47:46] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/31 07:47:46] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/31 07:47:46] detectron2.data.build INFO: Distribution of instances among all 7 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|   banana   | 176          |   apple    | 304          |   orange   | 851          |
| strawberry | 1022         |   tomato   | 790          |   lemon    | 219          |
|    pear    | 99           |            |              |            |              |
|   total    | 3461         |            |              |            |              |[0m
[03/31 07:47:46] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/31 07:47:46] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/31 07:47:46] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/31 07:47:46] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/31 07:47:46] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/31 07:47:59] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0247 s/iter. Inference: 0.0515 s/iter. Eval: 0.0004 s/iter. Total: 0.0767 s/iter. ETA=0:00:31
[03/31 07:48:04] detectron2.evaluation.evaluator INFO: Inference done 73/421. Dataloading: 0.0244 s/iter. Inference: 0.0555 s/iter. Eval: 0.0005 s/iter. Total: 0.0805 s/iter. ETA=0:00:28
[03/31 07:48:09] detectron2.evaluation.evaluator INFO: Inference done 123/421. Dataloading: 0.0249 s/iter. Inference: 0.0638 s/iter. Eval: 0.0005 s/iter. Total: 0.0893 s/iter. ETA=0:00:26
[03/31 07:48:14] detectron2.evaluation.evaluator INFO: Inference done 175/421. Dataloading: 0.0240 s/iter. Inference: 0.0671 s/iter. Eval: 0.0006 s/iter. Total: 0.0919 s/iter. ETA=0:00:22
[03/31 07:48:19] detectron2.evaluation.evaluator INFO: Inference done 221/421. Dataloading: 0.0266 s/iter. Inference: 0.0683 s/iter. Eval: 0.0006 s/iter. Total: 0.0956 s/iter. ETA=0:00:19
[03/31 07:48:24] detectron2.evaluation.evaluator INFO: Inference done 269/421. Dataloading: 0.0262 s/iter. Inference: 0.0709 s/iter. Eval: 0.0006 s/iter. Total: 0.0977 s/iter. ETA=0:00:14
[03/31 07:48:29] detectron2.evaluation.evaluator INFO: Inference done 317/421. Dataloading: 0.0258 s/iter. Inference: 0.0723 s/iter. Eval: 0.0006 s/iter. Total: 0.0988 s/iter. ETA=0:00:10
[03/31 07:48:34] detectron2.evaluation.evaluator INFO: Inference done 361/421. Dataloading: 0.0271 s/iter. Inference: 0.0728 s/iter. Eval: 0.0006 s/iter. Total: 0.1007 s/iter. ETA=0:00:06
[03/31 07:48:39] detectron2.evaluation.evaluator INFO: Inference done 405/421. Dataloading: 0.0283 s/iter. Inference: 0.0732 s/iter. Eval: 0.0007 s/iter. Total: 0.1022 s/iter. ETA=0:00:01
[03/31 07:48:42] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:43.235424 (0.103931 s / iter per device, on 2 devices)
[03/31 07:48:42] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:30 (0.073273 s / iter per device, on 2 devices)
[03/31 07:57:29] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/31 07:57:29] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/31 07:57:29] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/31 07:57:29] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/31 07:57:29] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/31 07:57:29] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/31 07:57:29] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/31 07:57:40] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0417 s/iter. Inference: 0.0870 s/iter. Eval: 0.0005 s/iter. Total: 0.1292 s/iter. ETA=0:00:52
[03/31 07:57:46] detectron2.evaluation.evaluator INFO: Inference done 47/421. Dataloading: 0.0608 s/iter. Inference: 0.0776 s/iter. Eval: 0.0006 s/iter. Total: 0.1391 s/iter. ETA=0:00:52
[03/31 07:57:51] detectron2.evaluation.evaluator INFO: Inference done 88/421. Dataloading: 0.0540 s/iter. Inference: 0.0770 s/iter. Eval: 0.0006 s/iter. Total: 0.1317 s/iter. ETA=0:00:43
[03/31 07:57:56] detectron2.evaluation.evaluator INFO: Inference done 130/421. Dataloading: 0.0486 s/iter. Inference: 0.0787 s/iter. Eval: 0.0006 s/iter. Total: 0.1279 s/iter. ETA=0:00:37
[03/31 07:58:01] detectron2.evaluation.evaluator INFO: Inference done 171/421. Dataloading: 0.0459 s/iter. Inference: 0.0801 s/iter. Eval: 0.0008 s/iter. Total: 0.1268 s/iter. ETA=0:00:31
[03/31 07:58:06] detectron2.evaluation.evaluator INFO: Inference done 211/421. Dataloading: 0.0459 s/iter. Inference: 0.0800 s/iter. Eval: 0.0008 s/iter. Total: 0.1267 s/iter. ETA=0:00:26
[03/31 07:58:11] detectron2.evaluation.evaluator INFO: Inference done 252/421. Dataloading: 0.0465 s/iter. Inference: 0.0789 s/iter. Eval: 0.0007 s/iter. Total: 0.1262 s/iter. ETA=0:00:21
[03/31 07:58:16] detectron2.evaluation.evaluator INFO: Inference done 296/421. Dataloading: 0.0455 s/iter. Inference: 0.0782 s/iter. Eval: 0.0008 s/iter. Total: 0.1246 s/iter. ETA=0:00:15
[03/31 07:58:21] detectron2.evaluation.evaluator INFO: Inference done 338/421. Dataloading: 0.0452 s/iter. Inference: 0.0778 s/iter. Eval: 0.0008 s/iter. Total: 0.1240 s/iter. ETA=0:00:10
[03/31 07:58:26] detectron2.evaluation.evaluator INFO: Inference done 382/421. Dataloading: 0.0452 s/iter. Inference: 0.0767 s/iter. Eval: 0.0008 s/iter. Total: 0.1228 s/iter. ETA=0:00:04
[03/31 07:58:31] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:51.544193 (0.123904 s / iter per device, on 2 devices)
[03/31 07:58:31] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:31 (0.076576 s / iter per device, on 2 devices)
[03/31 08:06:44] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/31 08:06:44] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/31 08:06:44] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/31 08:06:44] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/31 08:06:44] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/31 08:06:44] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/31 08:06:44] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/31 08:06:51] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0149 s/iter. Inference: 0.0655 s/iter. Eval: 0.0004 s/iter. Total: 0.0808 s/iter. ETA=0:00:33
[03/31 08:06:56] detectron2.evaluation.evaluator INFO: Inference done 59/421. Dataloading: 0.0255 s/iter. Inference: 0.0777 s/iter. Eval: 0.0006 s/iter. Total: 0.1039 s/iter. ETA=0:00:37
[03/31 08:07:01] detectron2.evaluation.evaluator INFO: Inference done 109/421. Dataloading: 0.0224 s/iter. Inference: 0.0793 s/iter. Eval: 0.0006 s/iter. Total: 0.1024 s/iter. ETA=0:00:31
[03/31 08:07:06] detectron2.evaluation.evaluator INFO: Inference done 164/421. Dataloading: 0.0222 s/iter. Inference: 0.0758 s/iter. Eval: 0.0005 s/iter. Total: 0.0987 s/iter. ETA=0:00:25
[03/31 08:07:11] detectron2.evaluation.evaluator INFO: Inference done 221/421. Dataloading: 0.0204 s/iter. Inference: 0.0750 s/iter. Eval: 0.0005 s/iter. Total: 0.0960 s/iter. ETA=0:00:19
[03/31 08:07:16] detectron2.evaluation.evaluator INFO: Inference done 275/421. Dataloading: 0.0208 s/iter. Inference: 0.0742 s/iter. Eval: 0.0005 s/iter. Total: 0.0956 s/iter. ETA=0:00:13
[03/31 08:07:21] detectron2.evaluation.evaluator INFO: Inference done 324/421. Dataloading: 0.0219 s/iter. Inference: 0.0742 s/iter. Eval: 0.0005 s/iter. Total: 0.0966 s/iter. ETA=0:00:09
[03/31 08:07:26] detectron2.evaluation.evaluator INFO: Inference done 372/421. Dataloading: 0.0222 s/iter. Inference: 0.0750 s/iter. Eval: 0.0005 s/iter. Total: 0.0978 s/iter. ETA=0:00:04
[03/31 08:07:31] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:40.994407 (0.098544 s / iter per device, on 2 devices)
[03/31 08:07:31] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:31 (0.074556 s / iter per device, on 2 devices)
[03/31 08:15:50] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/31 08:15:50] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/31 08:15:50] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/31 08:15:50] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/31 08:15:50] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/31 08:15:50] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/31 08:15:50] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/31 08:15:59] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0104 s/iter. Inference: 0.0963 s/iter. Eval: 0.0004 s/iter. Total: 0.1071 s/iter. ETA=0:00:43
[03/31 08:16:04] detectron2.evaluation.evaluator INFO: Inference done 58/421. Dataloading: 0.0275 s/iter. Inference: 0.0789 s/iter. Eval: 0.0006 s/iter. Total: 0.1071 s/iter. ETA=0:00:38
[03/31 08:16:09] detectron2.evaluation.evaluator INFO: Inference done 106/421. Dataloading: 0.0311 s/iter. Inference: 0.0743 s/iter. Eval: 0.0006 s/iter. Total: 0.1060 s/iter. ETA=0:00:33
[03/31 08:16:14] detectron2.evaluation.evaluator INFO: Inference done 161/421. Dataloading: 0.0277 s/iter. Inference: 0.0726 s/iter. Eval: 0.0006 s/iter. Total: 0.1010 s/iter. ETA=0:00:26
[03/31 08:16:19] detectron2.evaluation.evaluator INFO: Inference done 213/421. Dataloading: 0.0269 s/iter. Inference: 0.0728 s/iter. Eval: 0.0006 s/iter. Total: 0.1004 s/iter. ETA=0:00:20
[03/31 08:16:24] detectron2.evaluation.evaluator INFO: Inference done 258/421. Dataloading: 0.0286 s/iter. Inference: 0.0733 s/iter. Eval: 0.0006 s/iter. Total: 0.1026 s/iter. ETA=0:00:16
[03/31 08:16:29] detectron2.evaluation.evaluator INFO: Inference done 306/421. Dataloading: 0.0283 s/iter. Inference: 0.0741 s/iter. Eval: 0.0005 s/iter. Total: 0.1030 s/iter. ETA=0:00:11
[03/31 08:16:34] detectron2.evaluation.evaluator INFO: Inference done 357/421. Dataloading: 0.0277 s/iter. Inference: 0.0741 s/iter. Eval: 0.0006 s/iter. Total: 0.1024 s/iter. ETA=0:00:06
[03/31 08:16:39] detectron2.evaluation.evaluator INFO: Inference done 409/421. Dataloading: 0.0268 s/iter. Inference: 0.0744 s/iter. Eval: 0.0005 s/iter. Total: 0.1018 s/iter. ETA=0:00:01
[03/31 08:16:41] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:42.875166 (0.103065 s / iter per device, on 2 devices)
[03/31 08:16:41] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:30 (0.074241 s / iter per device, on 2 devices)
[03/31 08:24:59] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/31 08:24:59] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/31 08:24:59] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/31 08:24:59] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/31 08:24:59] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/31 08:24:59] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/31 08:24:59] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/31 08:25:06] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0083 s/iter. Inference: 0.0579 s/iter. Eval: 0.0004 s/iter. Total: 0.0666 s/iter. ETA=0:00:27
[03/31 08:25:11] detectron2.evaluation.evaluator INFO: Inference done 62/421. Dataloading: 0.0263 s/iter. Inference: 0.0692 s/iter. Eval: 0.0005 s/iter. Total: 0.0961 s/iter. ETA=0:00:34
[03/31 08:25:16] detectron2.evaluation.evaluator INFO: Inference done 117/421. Dataloading: 0.0228 s/iter. Inference: 0.0707 s/iter. Eval: 0.0004 s/iter. Total: 0.0941 s/iter. ETA=0:00:28
[03/31 08:25:21] detectron2.evaluation.evaluator INFO: Inference done 167/421. Dataloading: 0.0228 s/iter. Inference: 0.0727 s/iter. Eval: 0.0005 s/iter. Total: 0.0961 s/iter. ETA=0:00:24
[03/31 08:25:26] detectron2.evaluation.evaluator INFO: Inference done 217/421. Dataloading: 0.0223 s/iter. Inference: 0.0747 s/iter. Eval: 0.0005 s/iter. Total: 0.0977 s/iter. ETA=0:00:19
[03/31 08:25:31] detectron2.evaluation.evaluator INFO: Inference done 266/421. Dataloading: 0.0234 s/iter. Inference: 0.0746 s/iter. Eval: 0.0005 s/iter. Total: 0.0987 s/iter. ETA=0:00:15
[03/31 08:25:36] detectron2.evaluation.evaluator INFO: Inference done 319/421. Dataloading: 0.0230 s/iter. Inference: 0.0747 s/iter. Eval: 0.0005 s/iter. Total: 0.0984 s/iter. ETA=0:00:10
[03/31 08:25:41] detectron2.evaluation.evaluator INFO: Inference done 369/421. Dataloading: 0.0238 s/iter. Inference: 0.0743 s/iter. Eval: 0.0005 s/iter. Total: 0.0988 s/iter. ETA=0:00:05
[03/31 08:25:47] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:41.690247 (0.100217 s / iter per device, on 2 devices)
[03/31 08:25:47] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:30 (0.073466 s / iter per device, on 2 devices)
[03/31 08:34:04] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/31 08:34:04] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/31 08:34:04] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/31 08:34:04] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/31 08:34:04] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/31 08:34:04] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/31 08:34:04] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/31 08:34:15] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0147 s/iter. Inference: 0.0738 s/iter. Eval: 0.0003 s/iter. Total: 0.0888 s/iter. ETA=0:00:36
[03/31 08:34:20] detectron2.evaluation.evaluator INFO: Inference done 59/421. Dataloading: 0.0260 s/iter. Inference: 0.0760 s/iter. Eval: 0.0005 s/iter. Total: 0.1027 s/iter. ETA=0:00:37
[03/31 08:34:25] detectron2.evaluation.evaluator INFO: Inference done 112/421. Dataloading: 0.0257 s/iter. Inference: 0.0729 s/iter. Eval: 0.0005 s/iter. Total: 0.0992 s/iter. ETA=0:00:30
[03/31 08:34:30] detectron2.evaluation.evaluator INFO: Inference done 151/421. Dataloading: 0.0321 s/iter. Inference: 0.0743 s/iter. Eval: 0.0006 s/iter. Total: 0.1072 s/iter. ETA=0:00:28
[03/31 08:34:35] detectron2.evaluation.evaluator INFO: Inference done 198/421. Dataloading: 0.0321 s/iter. Inference: 0.0743 s/iter. Eval: 0.0005 s/iter. Total: 0.1071 s/iter. ETA=0:00:23
[03/31 08:34:40] detectron2.evaluation.evaluator INFO: Inference done 248/421. Dataloading: 0.0307 s/iter. Inference: 0.0746 s/iter. Eval: 0.0006 s/iter. Total: 0.1060 s/iter. ETA=0:00:18
[03/31 08:34:45] detectron2.evaluation.evaluator INFO: Inference done 300/421. Dataloading: 0.0294 s/iter. Inference: 0.0743 s/iter. Eval: 0.0005 s/iter. Total: 0.1044 s/iter. ETA=0:00:12
[03/31 08:34:50] detectron2.evaluation.evaluator INFO: Inference done 346/421. Dataloading: 0.0300 s/iter. Inference: 0.0744 s/iter. Eval: 0.0005 s/iter. Total: 0.1051 s/iter. ETA=0:00:07
[03/31 08:34:55] detectron2.evaluation.evaluator INFO: Inference done 396/421. Dataloading: 0.0289 s/iter. Inference: 0.0749 s/iter. Eval: 0.0005 s/iter. Total: 0.1045 s/iter. ETA=0:00:02
[03/31 08:34:58] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:43.893973 (0.105514 s / iter per device, on 2 devices)
[03/31 08:34:58] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:31 (0.075199 s / iter per device, on 2 devices)
[03/31 08:43:10] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/31 08:43:10] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/31 08:43:10] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/31 08:43:10] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/31 08:43:10] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/31 08:43:10] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/31 08:43:10] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/31 08:43:18] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0195 s/iter. Inference: 0.0537 s/iter. Eval: 0.0004 s/iter. Total: 0.0736 s/iter. ETA=0:00:30
[03/31 08:43:23] detectron2.evaluation.evaluator INFO: Inference done 57/421. Dataloading: 0.0308 s/iter. Inference: 0.0741 s/iter. Eval: 0.0006 s/iter. Total: 0.1056 s/iter. ETA=0:00:38
[03/31 08:43:28] detectron2.evaluation.evaluator INFO: Inference done 108/421. Dataloading: 0.0280 s/iter. Inference: 0.0735 s/iter. Eval: 0.0006 s/iter. Total: 0.1021 s/iter. ETA=0:00:31
[03/31 08:43:33] detectron2.evaluation.evaluator INFO: Inference done 159/421. Dataloading: 0.0268 s/iter. Inference: 0.0737 s/iter. Eval: 0.0006 s/iter. Total: 0.1012 s/iter. ETA=0:00:26
[03/31 08:43:38] detectron2.evaluation.evaluator INFO: Inference done 215/421. Dataloading: 0.0244 s/iter. Inference: 0.0732 s/iter. Eval: 0.0005 s/iter. Total: 0.0982 s/iter. ETA=0:00:20
[03/31 08:43:43] detectron2.evaluation.evaluator INFO: Inference done 265/421. Dataloading: 0.0257 s/iter. Inference: 0.0724 s/iter. Eval: 0.0005 s/iter. Total: 0.0987 s/iter. ETA=0:00:15
[03/31 08:43:48] detectron2.evaluation.evaluator INFO: Inference done 319/421. Dataloading: 0.0246 s/iter. Inference: 0.0727 s/iter. Eval: 0.0005 s/iter. Total: 0.0979 s/iter. ETA=0:00:09
[03/31 08:43:53] detectron2.evaluation.evaluator INFO: Inference done 369/421. Dataloading: 0.0245 s/iter. Inference: 0.0734 s/iter. Eval: 0.0005 s/iter. Total: 0.0984 s/iter. ETA=0:00:05
[03/31 08:43:58] detectron2.evaluation.evaluator INFO: Inference done 417/421. Dataloading: 0.0256 s/iter. Inference: 0.0731 s/iter. Eval: 0.0005 s/iter. Total: 0.0993 s/iter. ETA=0:00:00
[03/31 08:43:59] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:41.970450 (0.100891 s / iter per device, on 2 devices)
[03/31 08:43:59] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:30 (0.073045 s / iter per device, on 2 devices)
[03/31 08:52:18] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/31 08:52:18] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/31 08:52:18] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/31 08:52:18] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/31 08:52:18] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/31 08:52:18] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/31 08:52:18] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/31 08:52:32] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0278 s/iter. Inference: 0.0615 s/iter. Eval: 0.0004 s/iter. Total: 0.0896 s/iter. ETA=0:00:36
[03/31 08:52:37] detectron2.evaluation.evaluator INFO: Inference done 56/421. Dataloading: 0.0301 s/iter. Inference: 0.0783 s/iter. Eval: 0.0008 s/iter. Total: 0.1093 s/iter. ETA=0:00:39
[03/31 08:52:42] detectron2.evaluation.evaluator INFO: Inference done 104/421. Dataloading: 0.0283 s/iter. Inference: 0.0784 s/iter. Eval: 0.0008 s/iter. Total: 0.1076 s/iter. ETA=0:00:34
[03/31 08:52:47] detectron2.evaluation.evaluator INFO: Inference done 160/421. Dataloading: 0.0252 s/iter. Inference: 0.0753 s/iter. Eval: 0.0007 s/iter. Total: 0.1013 s/iter. ETA=0:00:26
[03/31 08:52:52] detectron2.evaluation.evaluator INFO: Inference done 211/421. Dataloading: 0.0225 s/iter. Inference: 0.0775 s/iter. Eval: 0.0007 s/iter. Total: 0.1007 s/iter. ETA=0:00:21
[03/31 08:52:57] detectron2.evaluation.evaluator INFO: Inference done 264/421. Dataloading: 0.0215 s/iter. Inference: 0.0770 s/iter. Eval: 0.0009 s/iter. Total: 0.0995 s/iter. ETA=0:00:15
[03/31 08:53:02] detectron2.evaluation.evaluator INFO: Inference done 319/421. Dataloading: 0.0205 s/iter. Inference: 0.0765 s/iter. Eval: 0.0009 s/iter. Total: 0.0980 s/iter. ETA=0:00:09
[03/31 08:53:07] detectron2.evaluation.evaluator INFO: Inference done 374/421. Dataloading: 0.0207 s/iter. Inference: 0.0753 s/iter. Eval: 0.0008 s/iter. Total: 0.0970 s/iter. ETA=0:00:04
[03/31 08:53:13] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:41.176852 (0.098983 s / iter per device, on 2 devices)
[03/31 08:53:13] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:31 (0.075461 s / iter per device, on 2 devices)
[03/31 09:01:29] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/31 09:01:29] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/31 09:01:29] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/31 09:01:29] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/31 09:01:29] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/31 09:01:29] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/31 09:01:29] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/31 09:01:37] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0115 s/iter. Inference: 0.0575 s/iter. Eval: 0.0004 s/iter. Total: 0.0695 s/iter. ETA=0:00:28
[03/31 09:01:42] detectron2.evaluation.evaluator INFO: Inference done 56/421. Dataloading: 0.0312 s/iter. Inference: 0.0756 s/iter. Eval: 0.0008 s/iter. Total: 0.1077 s/iter. ETA=0:00:39
[03/31 09:01:47] detectron2.evaluation.evaluator INFO: Inference done 105/421. Dataloading: 0.0280 s/iter. Inference: 0.0767 s/iter. Eval: 0.0006 s/iter. Total: 0.1055 s/iter. ETA=0:00:33
[03/31 09:01:52] detectron2.evaluation.evaluator INFO: Inference done 153/421. Dataloading: 0.0275 s/iter. Inference: 0.0775 s/iter. Eval: 0.0006 s/iter. Total: 0.1057 s/iter. ETA=0:00:28
[03/31 09:01:57] detectron2.evaluation.evaluator INFO: Inference done 201/421. Dataloading: 0.0263 s/iter. Inference: 0.0786 s/iter. Eval: 0.0005 s/iter. Total: 0.1055 s/iter. ETA=0:00:23
[03/31 09:02:03] detectron2.evaluation.evaluator INFO: Inference done 258/421. Dataloading: 0.0235 s/iter. Inference: 0.0776 s/iter. Eval: 0.0005 s/iter. Total: 0.1017 s/iter. ETA=0:00:16
[03/31 09:02:08] detectron2.evaluation.evaluator INFO: Inference done 302/421. Dataloading: 0.0256 s/iter. Inference: 0.0775 s/iter. Eval: 0.0005 s/iter. Total: 0.1037 s/iter. ETA=0:00:12
[03/31 09:02:13] detectron2.evaluation.evaluator INFO: Inference done 356/421. Dataloading: 0.0255 s/iter. Inference: 0.0760 s/iter. Eval: 0.0005 s/iter. Total: 0.1021 s/iter. ETA=0:00:06
[03/31 09:02:18] detectron2.evaluation.evaluator INFO: Inference done 408/421. Dataloading: 0.0247 s/iter. Inference: 0.0760 s/iter. Eval: 0.0006 s/iter. Total: 0.1014 s/iter. ETA=0:00:01
[03/31 09:02:19] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:42.522144 (0.102217 s / iter per device, on 2 devices)
[03/31 09:02:19] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:31 (0.075806 s / iter per device, on 2 devices)
[03/31 09:10:38] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/31 09:10:38] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/31 09:10:38] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/31 09:10:38] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/31 09:10:38] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/31 09:10:38] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/31 09:10:38] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/31 09:10:51] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0365 s/iter. Inference: 0.0716 s/iter. Eval: 0.0004 s/iter. Total: 0.1085 s/iter. ETA=0:00:44
[03/31 09:10:56] detectron2.evaluation.evaluator INFO: Inference done 65/421. Dataloading: 0.0244 s/iter. Inference: 0.0702 s/iter. Eval: 0.0004 s/iter. Total: 0.0953 s/iter. ETA=0:00:33
[03/31 09:11:01] detectron2.evaluation.evaluator INFO: Inference done 115/421. Dataloading: 0.0243 s/iter. Inference: 0.0728 s/iter. Eval: 0.0005 s/iter. Total: 0.0978 s/iter. ETA=0:00:29
[03/31 09:11:06] detectron2.evaluation.evaluator INFO: Inference done 163/421. Dataloading: 0.0244 s/iter. Inference: 0.0752 s/iter. Eval: 0.0004 s/iter. Total: 0.1003 s/iter. ETA=0:00:25
[03/31 09:11:11] detectron2.evaluation.evaluator INFO: Inference done 214/421. Dataloading: 0.0257 s/iter. Inference: 0.0738 s/iter. Eval: 0.0005 s/iter. Total: 0.1001 s/iter. ETA=0:00:20
[03/31 09:11:16] detectron2.evaluation.evaluator INFO: Inference done 267/421. Dataloading: 0.0238 s/iter. Inference: 0.0747 s/iter. Eval: 0.0005 s/iter. Total: 0.0991 s/iter. ETA=0:00:15
[03/31 09:11:21] detectron2.evaluation.evaluator INFO: Inference done 320/421. Dataloading: 0.0233 s/iter. Inference: 0.0745 s/iter. Eval: 0.0005 s/iter. Total: 0.0985 s/iter. ETA=0:00:09
[03/31 09:11:26] detectron2.evaluation.evaluator INFO: Inference done 372/421. Dataloading: 0.0232 s/iter. Inference: 0.0744 s/iter. Eval: 0.0005 s/iter. Total: 0.0983 s/iter. ETA=0:00:04
[03/31 09:11:31] detectron2.evaluation.evaluator INFO: Inference done 418/421. Dataloading: 0.0241 s/iter. Inference: 0.0749 s/iter. Eval: 0.0005 s/iter. Total: 0.0996 s/iter. ETA=0:00:00
[03/31 09:11:32] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:41.948425 (0.100838 s / iter per device, on 2 devices)
[03/31 09:11:32] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:31 (0.074839 s / iter per device, on 2 devices)
[03/31 09:19:48] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/31 09:19:48] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/31 09:19:48] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/31 09:19:48] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/31 09:19:48] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/31 09:19:48] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/31 09:19:48] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/31 09:19:54] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0108 s/iter. Inference: 0.0705 s/iter. Eval: 0.0004 s/iter. Total: 0.0817 s/iter. ETA=0:00:33
[03/31 09:20:00] detectron2.evaluation.evaluator INFO: Inference done 59/421. Dataloading: 0.0311 s/iter. Inference: 0.0706 s/iter. Eval: 0.0004 s/iter. Total: 0.1022 s/iter. ETA=0:00:37
[03/31 09:20:05] detectron2.evaluation.evaluator INFO: Inference done 104/421. Dataloading: 0.0311 s/iter. Inference: 0.0748 s/iter. Eval: 0.0004 s/iter. Total: 0.1063 s/iter. ETA=0:00:33
[03/31 09:20:10] detectron2.evaluation.evaluator INFO: Inference done 155/421. Dataloading: 0.0296 s/iter. Inference: 0.0740 s/iter. Eval: 0.0004 s/iter. Total: 0.1042 s/iter. ETA=0:00:27
[03/31 09:20:15] detectron2.evaluation.evaluator INFO: Inference done 213/421. Dataloading: 0.0253 s/iter. Inference: 0.0735 s/iter. Eval: 0.0005 s/iter. Total: 0.0994 s/iter. ETA=0:00:20
[03/31 09:20:20] detectron2.evaluation.evaluator INFO: Inference done 262/421. Dataloading: 0.0258 s/iter. Inference: 0.0736 s/iter. Eval: 0.0005 s/iter. Total: 0.1000 s/iter. ETA=0:00:15
[03/31 09:20:25] detectron2.evaluation.evaluator INFO: Inference done 311/421. Dataloading: 0.0251 s/iter. Inference: 0.0747 s/iter. Eval: 0.0005 s/iter. Total: 0.1004 s/iter. ETA=0:00:11
[03/31 09:20:30] detectron2.evaluation.evaluator INFO: Inference done 356/421. Dataloading: 0.0255 s/iter. Inference: 0.0756 s/iter. Eval: 0.0005 s/iter. Total: 0.1018 s/iter. ETA=0:00:06
[03/31 09:20:35] detectron2.evaluation.evaluator INFO: Inference done 405/421. Dataloading: 0.0260 s/iter. Inference: 0.0755 s/iter. Eval: 0.0005 s/iter. Total: 0.1021 s/iter. ETA=0:00:01
[03/31 09:20:37] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:43.252568 (0.103973 s / iter per device, on 2 devices)
[03/31 09:20:37] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:31 (0.075365 s / iter per device, on 2 devices)
[03/31 09:29:00] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/31 09:29:00] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/31 09:29:00] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/31 09:29:00] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/31 09:29:00] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/31 09:29:00] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/31 09:29:00] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/31 09:29:11] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0210 s/iter. Inference: 0.0819 s/iter. Eval: 0.0004 s/iter. Total: 0.1033 s/iter. ETA=0:00:42
[03/31 09:29:16] detectron2.evaluation.evaluator INFO: Inference done 56/421. Dataloading: 0.0295 s/iter. Inference: 0.0814 s/iter. Eval: 0.0005 s/iter. Total: 0.1117 s/iter. ETA=0:00:40
[03/31 09:29:21] detectron2.evaluation.evaluator INFO: Inference done 106/421. Dataloading: 0.0281 s/iter. Inference: 0.0775 s/iter. Eval: 0.0005 s/iter. Total: 0.1062 s/iter. ETA=0:00:33
[03/31 09:29:26] detectron2.evaluation.evaluator INFO: Inference done 153/421. Dataloading: 0.0284 s/iter. Inference: 0.0779 s/iter. Eval: 0.0005 s/iter. Total: 0.1070 s/iter. ETA=0:00:28
[03/31 09:29:31] detectron2.evaluation.evaluator INFO: Inference done 206/421. Dataloading: 0.0280 s/iter. Inference: 0.0756 s/iter. Eval: 0.0005 s/iter. Total: 0.1042 s/iter. ETA=0:00:22
[03/31 09:29:36] detectron2.evaluation.evaluator INFO: Inference done 256/421. Dataloading: 0.0264 s/iter. Inference: 0.0766 s/iter. Eval: 0.0005 s/iter. Total: 0.1036 s/iter. ETA=0:00:17
[03/31 09:29:41] detectron2.evaluation.evaluator INFO: Inference done 303/421. Dataloading: 0.0273 s/iter. Inference: 0.0763 s/iter. Eval: 0.0004 s/iter. Total: 0.1042 s/iter. ETA=0:00:12
[03/31 09:29:46] detectron2.evaluation.evaluator INFO: Inference done 351/421. Dataloading: 0.0268 s/iter. Inference: 0.0768 s/iter. Eval: 0.0005 s/iter. Total: 0.1042 s/iter. ETA=0:00:07
[03/31 09:29:51] detectron2.evaluation.evaluator INFO: Inference done 399/421. Dataloading: 0.0275 s/iter. Inference: 0.0762 s/iter. Eval: 0.0005 s/iter. Total: 0.1043 s/iter. ETA=0:00:02
[03/31 09:29:54] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:43.955441 (0.105662 s / iter per device, on 2 devices)
[03/31 09:29:54] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:31 (0.075623 s / iter per device, on 2 devices)
[03/31 09:38:27] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/31 09:38:27] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/31 09:38:27] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/31 09:38:27] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/31 09:38:27] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/31 09:38:27] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/31 09:38:27] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/31 09:38:38] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0118 s/iter. Inference: 0.0629 s/iter. Eval: 0.0003 s/iter. Total: 0.0750 s/iter. ETA=0:00:30
[03/31 09:38:43] detectron2.evaluation.evaluator INFO: Inference done 59/421. Dataloading: 0.0285 s/iter. Inference: 0.0727 s/iter. Eval: 0.0003 s/iter. Total: 0.1016 s/iter. ETA=0:00:36
[03/31 09:38:48] detectron2.evaluation.evaluator INFO: Inference done 112/421. Dataloading: 0.0254 s/iter. Inference: 0.0722 s/iter. Eval: 0.0003 s/iter. Total: 0.0981 s/iter. ETA=0:00:30
[03/31 09:38:53] detectron2.evaluation.evaluator INFO: Inference done 164/421. Dataloading: 0.0254 s/iter. Inference: 0.0717 s/iter. Eval: 0.0003 s/iter. Total: 0.0975 s/iter. ETA=0:00:25
[03/31 09:38:58] detectron2.evaluation.evaluator INFO: Inference done 211/421. Dataloading: 0.0272 s/iter. Inference: 0.0724 s/iter. Eval: 0.0004 s/iter. Total: 0.1001 s/iter. ETA=0:00:21
[03/31 09:39:03] detectron2.evaluation.evaluator INFO: Inference done 261/421. Dataloading: 0.0264 s/iter. Inference: 0.0737 s/iter. Eval: 0.0004 s/iter. Total: 0.1006 s/iter. ETA=0:00:16
[03/31 09:39:08] detectron2.evaluation.evaluator INFO: Inference done 315/421. Dataloading: 0.0253 s/iter. Inference: 0.0736 s/iter. Eval: 0.0004 s/iter. Total: 0.0994 s/iter. ETA=0:00:10
[03/31 09:39:13] detectron2.evaluation.evaluator INFO: Inference done 362/421. Dataloading: 0.0256 s/iter. Inference: 0.0741 s/iter. Eval: 0.0006 s/iter. Total: 0.1004 s/iter. ETA=0:00:05
[03/31 09:39:18] detectron2.evaluation.evaluator INFO: Inference done 412/421. Dataloading: 0.0262 s/iter. Inference: 0.0737 s/iter. Eval: 0.0006 s/iter. Total: 0.1006 s/iter. ETA=0:00:00
[03/31 09:39:20] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:42.413938 (0.101957 s / iter per device, on 2 devices)
[03/31 09:39:20] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:30 (0.073632 s / iter per device, on 2 devices)
[03/31 09:47:41] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/31 09:47:41] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/31 09:47:41] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/31 09:47:41] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/31 09:47:41] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/31 09:47:41] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/31 09:47:41] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/31 09:48:00] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0141 s/iter. Inference: 0.0757 s/iter. Eval: 0.0003 s/iter. Total: 0.0902 s/iter. ETA=0:00:36
[03/31 09:48:05] detectron2.evaluation.evaluator INFO: Inference done 57/421. Dataloading: 0.0255 s/iter. Inference: 0.0808 s/iter. Eval: 0.0005 s/iter. Total: 0.1071 s/iter. ETA=0:00:38
[03/31 09:48:10] detectron2.evaluation.evaluator INFO: Inference done 112/421. Dataloading: 0.0236 s/iter. Inference: 0.0746 s/iter. Eval: 0.0004 s/iter. Total: 0.0988 s/iter. ETA=0:00:30
[03/31 09:48:15] detectron2.evaluation.evaluator INFO: Inference done 165/421. Dataloading: 0.0220 s/iter. Inference: 0.0748 s/iter. Eval: 0.0005 s/iter. Total: 0.0975 s/iter. ETA=0:00:24
[03/31 09:48:20] detectron2.evaluation.evaluator INFO: Inference done 217/421. Dataloading: 0.0226 s/iter. Inference: 0.0745 s/iter. Eval: 0.0006 s/iter. Total: 0.0979 s/iter. ETA=0:00:19
[03/31 09:48:25] detectron2.evaluation.evaluator INFO: Inference done 267/421. Dataloading: 0.0230 s/iter. Inference: 0.0747 s/iter. Eval: 0.0006 s/iter. Total: 0.0985 s/iter. ETA=0:00:15
[03/31 09:48:30] detectron2.evaluation.evaluator INFO: Inference done 321/421. Dataloading: 0.0228 s/iter. Inference: 0.0740 s/iter. Eval: 0.0006 s/iter. Total: 0.0976 s/iter. ETA=0:00:09
[03/31 09:48:35] detectron2.evaluation.evaluator INFO: Inference done 373/421. Dataloading: 0.0229 s/iter. Inference: 0.0738 s/iter. Eval: 0.0006 s/iter. Total: 0.0974 s/iter. ETA=0:00:04
[03/31 09:48:41] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:41.162430 (0.098948 s / iter per device, on 2 devices)
[03/31 09:48:41] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:30 (0.074259 s / iter per device, on 2 devices)
[03/31 09:56:59] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/31 09:56:59] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/31 09:56:59] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/31 09:56:59] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/31 09:56:59] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/31 09:56:59] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/31 09:56:59] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/31 09:57:06] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0204 s/iter. Inference: 0.0621 s/iter. Eval: 0.0003 s/iter. Total: 0.0828 s/iter. ETA=0:00:33
[03/31 09:57:11] detectron2.evaluation.evaluator INFO: Inference done 58/421. Dataloading: 0.0303 s/iter. Inference: 0.0744 s/iter. Eval: 0.0003 s/iter. Total: 0.1051 s/iter. ETA=0:00:38
[03/31 09:57:16] detectron2.evaluation.evaluator INFO: Inference done 111/421. Dataloading: 0.0269 s/iter. Inference: 0.0730 s/iter. Eval: 0.0004 s/iter. Total: 0.1004 s/iter. ETA=0:00:31
[03/31 09:57:22] detectron2.evaluation.evaluator INFO: Inference done 165/421. Dataloading: 0.0257 s/iter. Inference: 0.0722 s/iter. Eval: 0.0005 s/iter. Total: 0.0985 s/iter. ETA=0:00:25
[03/31 09:57:27] detectron2.evaluation.evaluator INFO: Inference done 205/421. Dataloading: 0.0310 s/iter. Inference: 0.0724 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:00:22
[03/31 09:57:32] detectron2.evaluation.evaluator INFO: Inference done 257/421. Dataloading: 0.0293 s/iter. Inference: 0.0728 s/iter. Eval: 0.0005 s/iter. Total: 0.1027 s/iter. ETA=0:00:16
[03/31 09:57:37] detectron2.evaluation.evaluator INFO: Inference done 305/421. Dataloading: 0.0284 s/iter. Inference: 0.0741 s/iter. Eval: 0.0005 s/iter. Total: 0.1031 s/iter. ETA=0:00:11
[03/31 09:57:42] detectron2.evaluation.evaluator INFO: Inference done 352/421. Dataloading: 0.0284 s/iter. Inference: 0.0747 s/iter. Eval: 0.0005 s/iter. Total: 0.1036 s/iter. ETA=0:00:07
[03/31 09:57:47] detectron2.evaluation.evaluator INFO: Inference done 397/421. Dataloading: 0.0292 s/iter. Inference: 0.0747 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:00:02
[03/31 09:57:49] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:43.480464 (0.104520 s / iter per device, on 2 devices)
[03/31 09:57:49] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:30 (0.074355 s / iter per device, on 2 devices)
[03/31 10:06:07] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/31 10:06:07] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/31 10:06:07] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/31 10:06:07] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/31 10:06:07] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/31 10:06:07] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/31 10:06:07] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/31 10:06:21] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0165 s/iter. Inference: 0.0683 s/iter. Eval: 0.0004 s/iter. Total: 0.0852 s/iter. ETA=0:00:34
[03/31 10:06:26] detectron2.evaluation.evaluator INFO: Inference done 63/421. Dataloading: 0.0218 s/iter. Inference: 0.0746 s/iter. Eval: 0.0004 s/iter. Total: 0.0969 s/iter. ETA=0:00:34
[03/31 10:06:31] detectron2.evaluation.evaluator INFO: Inference done 113/421. Dataloading: 0.0230 s/iter. Inference: 0.0764 s/iter. Eval: 0.0004 s/iter. Total: 0.0998 s/iter. ETA=0:00:30
[03/31 10:06:36] detectron2.evaluation.evaluator INFO: Inference done 167/421. Dataloading: 0.0215 s/iter. Inference: 0.0758 s/iter. Eval: 0.0004 s/iter. Total: 0.0977 s/iter. ETA=0:00:24
[03/31 10:06:41] detectron2.evaluation.evaluator INFO: Inference done 218/421. Dataloading: 0.0233 s/iter. Inference: 0.0741 s/iter. Eval: 0.0004 s/iter. Total: 0.0979 s/iter. ETA=0:00:19
[03/31 10:06:46] detectron2.evaluation.evaluator INFO: Inference done 269/421. Dataloading: 0.0234 s/iter. Inference: 0.0742 s/iter. Eval: 0.0004 s/iter. Total: 0.0980 s/iter. ETA=0:00:14
[03/31 10:06:51] detectron2.evaluation.evaluator INFO: Inference done 324/421. Dataloading: 0.0218 s/iter. Inference: 0.0745 s/iter. Eval: 0.0004 s/iter. Total: 0.0969 s/iter. ETA=0:00:09
[03/31 10:06:57] detectron2.evaluation.evaluator INFO: Inference done 378/421. Dataloading: 0.0217 s/iter. Inference: 0.0742 s/iter. Eval: 0.0004 s/iter. Total: 0.0964 s/iter. ETA=0:00:04
[03/31 10:07:02] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:41.034381 (0.098640 s / iter per device, on 2 devices)
[03/31 10:07:02] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:30 (0.073971 s / iter per device, on 2 devices)
[03/31 10:15:26] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/31 10:15:26] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/31 10:15:26] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/31 10:15:26] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/31 10:15:26] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/31 10:15:26] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/31 10:15:26] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/31 10:15:33] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0457 s/iter. Inference: 0.0767 s/iter. Eval: 0.0003 s/iter. Total: 0.1228 s/iter. ETA=0:00:50
[03/31 10:15:38] detectron2.evaluation.evaluator INFO: Inference done 62/421. Dataloading: 0.0233 s/iter. Inference: 0.0782 s/iter. Eval: 0.0008 s/iter. Total: 0.1025 s/iter. ETA=0:00:36
[03/31 10:15:43] detectron2.evaluation.evaluator INFO: Inference done 109/421. Dataloading: 0.0262 s/iter. Inference: 0.0777 s/iter. Eval: 0.0006 s/iter. Total: 0.1046 s/iter. ETA=0:00:32
[03/31 10:15:48] detectron2.evaluation.evaluator INFO: Inference done 155/421. Dataloading: 0.0252 s/iter. Inference: 0.0800 s/iter. Eval: 0.0006 s/iter. Total: 0.1058 s/iter. ETA=0:00:28
[03/31 10:15:53] detectron2.evaluation.evaluator INFO: Inference done 201/421. Dataloading: 0.0260 s/iter. Inference: 0.0803 s/iter. Eval: 0.0005 s/iter. Total: 0.1069 s/iter. ETA=0:00:23
[03/31 10:15:58] detectron2.evaluation.evaluator INFO: Inference done 250/421. Dataloading: 0.0254 s/iter. Inference: 0.0801 s/iter. Eval: 0.0005 s/iter. Total: 0.1061 s/iter. ETA=0:00:18
[03/31 10:16:03] detectron2.evaluation.evaluator INFO: Inference done 296/421. Dataloading: 0.0259 s/iter. Inference: 0.0800 s/iter. Eval: 0.0005 s/iter. Total: 0.1065 s/iter. ETA=0:00:13
[03/31 10:16:09] detectron2.evaluation.evaluator INFO: Inference done 348/421. Dataloading: 0.0252 s/iter. Inference: 0.0794 s/iter. Eval: 0.0005 s/iter. Total: 0.1051 s/iter. ETA=0:00:07
[03/31 10:16:14] detectron2.evaluation.evaluator INFO: Inference done 396/421. Dataloading: 0.0259 s/iter. Inference: 0.0787 s/iter. Eval: 0.0005 s/iter. Total: 0.1052 s/iter. ETA=0:00:02
[03/31 10:16:16] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:43.952360 (0.105655 s / iter per device, on 2 devices)
[03/31 10:16:16] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:32 (0.077764 s / iter per device, on 2 devices)
[03/31 10:24:30] detectron2.engine.hooks INFO: Overall training speed: 8998 iterations in 2:28:44 (0.9919 s / it)
[03/31 10:24:30] detectron2.engine.hooks INFO: Total training time: 2:45:01 (0:16:16 on hooks)
[03/31 10:24:31] detectron2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[03/31 10:24:31] detectron2.data.datasets.coco INFO: Loaded 842 images in COCO format from ./data/openim_id/COCO-Format/val_coco_format.json
[03/31 10:24:31] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=1333, sample_style='choice')]
[03/31 10:24:31] detectron2.data.common INFO: Serializing 842 elements to byte tensors and concatenating them all ...
[03/31 10:24:31] detectron2.data.common INFO: Serialized dataset takes 0.37 MiB
[03/31 10:24:31] detectron2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[03/31 10:24:31] detectron2.evaluation.evaluator INFO: Start inference on 421 batches
[03/31 10:24:46] detectron2.evaluation.evaluator INFO: Inference done 11/421. Dataloading: 0.0195 s/iter. Inference: 0.0587 s/iter. Eval: 0.0003 s/iter. Total: 0.0785 s/iter. ETA=0:00:32
[03/31 10:24:51] detectron2.evaluation.evaluator INFO: Inference done 58/421. Dataloading: 0.0279 s/iter. Inference: 0.0760 s/iter. Eval: 0.0004 s/iter. Total: 0.1044 s/iter. ETA=0:00:37
[03/31 10:24:56] detectron2.evaluation.evaluator INFO: Inference done 106/421. Dataloading: 0.0296 s/iter. Inference: 0.0744 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:00:32
[03/31 10:25:01] detectron2.evaluation.evaluator INFO: Inference done 156/421. Dataloading: 0.0278 s/iter. Inference: 0.0749 s/iter. Eval: 0.0005 s/iter. Total: 0.1033 s/iter. ETA=0:00:27
[03/31 10:25:06] detectron2.evaluation.evaluator INFO: Inference done 206/421. Dataloading: 0.0269 s/iter. Inference: 0.0751 s/iter. Eval: 0.0005 s/iter. Total: 0.1028 s/iter. ETA=0:00:22
[03/31 10:25:11] detectron2.evaluation.evaluator INFO: Inference done 255/421. Dataloading: 0.0266 s/iter. Inference: 0.0754 s/iter. Eval: 0.0005 s/iter. Total: 0.1028 s/iter. ETA=0:00:17
[03/31 10:25:16] detectron2.evaluation.evaluator INFO: Inference done 311/421. Dataloading: 0.0252 s/iter. Inference: 0.0745 s/iter. Eval: 0.0005 s/iter. Total: 0.1004 s/iter. ETA=0:00:11
[03/31 10:25:21] detectron2.evaluation.evaluator INFO: Inference done 361/421. Dataloading: 0.0260 s/iter. Inference: 0.0738 s/iter. Eval: 0.0005 s/iter. Total: 0.1005 s/iter. ETA=0:00:06
[03/31 10:25:26] detectron2.evaluation.evaluator INFO: Inference done 415/421. Dataloading: 0.0251 s/iter. Inference: 0.0739 s/iter. Eval: 0.0004 s/iter. Total: 0.0997 s/iter. ETA=0:00:00
[03/31 10:25:27] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:42.184156 (0.101404 s / iter per device, on 2 devices)
[03/31 10:25:27] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:30 (0.074405 s / iter per device, on 2 devices)
